{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konstanta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'ulos/dataset/'\n",
    "\n",
    "IMG_SIZE = 64\n",
    "NUM_CLASS = 6\n",
    "NUM_KFOLD = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "### Memuat dataset dan memilih data training dan testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:28<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "img_data_list = []\n",
    "for dataset in tqdm(os.listdir(data_path)):\n",
    "    path = os.path.join(data_path, dataset)\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img_data_list.append(img)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,), dtype='int64')\n",
    "names = ['Bintang Maratur', 'Mangiring', 'Ragi Hotang', 'Ragi Idup', 'Sadum', 'Sibolang']\n",
    "labels[0:17]=0\n",
    "labels[17:73]=2\n",
    "labels[73:79]=3\n",
    "labels[79:124]=1\n",
    "labels[124:214]=4\n",
    "labels[214:225]=5\n",
    "\n",
    "#one hot encoding\n",
    "Y = np_utils.to_categorical(labels,NUM_CLASS)\n",
    "\n",
    "#shuffle dataset\n",
    "x,y = shuffle(img_data, Y, random_state=2)\n",
    "\n",
    "#Take the shape of the image\n",
    "input_shape=img_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat model CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(InputLayer(input_shape=input_shape))\n",
    "    #1\n",
    "    model.add(Conv2D(filters=64, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "\n",
    "    #2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), strides=2, padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "    #3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "    \n",
    "    #4\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=2, padding='same'))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(NUM_CLASS, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan training data dengan menerapkan cross validation K-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasi ke-1\n",
      "Train : [  1   2   3   5   7   8   9  10  13  15  16  17  18  19  22  23  24  25\n",
      "  26  27  28  29  30  31  33  34  35  36  37  38  39  40  41  43  44  45\n",
      "  46  47  48  50  51  53  54  55  56  57  58  59  60  62  63  64  65  66\n",
      "  67  68  69  71  72  73  75  76  77  78  79  80  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  96  97 101 102 103 104 105 106 108 112 113\n",
      " 114 116 117 121 122 125 126 127 128 129 130 131 132 135 136 137 138 140\n",
      " 141 143 144 145 146 147 149 150 151 152 153 154 155 157 159 161 162 163\n",
      " 164 165 166 167 168 169 170 173 174 175 176 177 179 181 183 184 185 186\n",
      " 187 188 189 190 191 192 194 195 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223]\n",
      "Test : [  0   4   6  11  12  14  20  21  32  42  49  52  61  70  74  81  95  98\n",
      "  99 100 107 109 110 111 115 118 119 120 123 124 133 134 139 142 148 156\n",
      " 158 160 171 172 178 180 182 193 196 224]\n",
      "Train on 179 samples, validate on 46 samples\n",
      "Epoch 1/50\n",
      "179/179 [==============================] - ETA: 10s - loss: 1.8116 - acc: 0.12 - ETA: 4s - loss: 1.7723 - acc: 0.1800 - ETA: 2s - loss: 1.7473 - acc: 0.226 - ETA: 1s - loss: 1.6471 - acc: 0.290 - ETA: 1s - loss: 1.5306 - acc: 0.336 - ETA: 0s - loss: 1.6772 - acc: 0.313 - ETA: 0s - loss: 1.6898 - acc: 0.314 - 3s 19ms/step - loss: 1.7040 - acc: 0.3128 - val_loss: 1.5354 - val_acc: 0.1522\n",
      "Epoch 2/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.6509 - acc: 0.160 - ETA: 1s - loss: 1.5943 - acc: 0.240 - ETA: 0s - loss: 1.6223 - acc: 0.226 - ETA: 0s - loss: 1.6237 - acc: 0.280 - ETA: 0s - loss: 1.6315 - acc: 0.280 - ETA: 0s - loss: 1.6511 - acc: 0.280 - ETA: 0s - loss: 1.6545 - acc: 0.262 - 2s 11ms/step - loss: 1.6523 - acc: 0.2682 - val_loss: 1.5654 - val_acc: 0.1522\n",
      "Epoch 3/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.7425 - acc: 0.200 - ETA: 1s - loss: 1.5922 - acc: 0.280 - ETA: 1s - loss: 1.6081 - acc: 0.266 - ETA: 0s - loss: 1.5394 - acc: 0.280 - ETA: 0s - loss: 1.5204 - acc: 0.272 - ETA: 0s - loss: 1.5683 - acc: 0.246 - ETA: 0s - loss: 1.5901 - acc: 0.251 - 2s 10ms/step - loss: 1.5807 - acc: 0.2514 - val_loss: 1.2954 - val_acc: 0.5435\n",
      "Epoch 4/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.6888 - acc: 0.320 - ETA: 1s - loss: 1.6737 - acc: 0.320 - ETA: 1s - loss: 1.5558 - acc: 0.360 - ETA: 0s - loss: 1.5629 - acc: 0.350 - ETA: 0s - loss: 1.5344 - acc: 0.360 - ETA: 0s - loss: 1.5376 - acc: 0.360 - ETA: 0s - loss: 1.5127 - acc: 0.377 - 2s 12ms/step - loss: 1.5137 - acc: 0.3799 - val_loss: 1.3288 - val_acc: 0.5435\n",
      "Epoch 5/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3853 - acc: 0.480 - ETA: 1s - loss: 1.4384 - acc: 0.420 - ETA: 1s - loss: 1.5076 - acc: 0.360 - ETA: 0s - loss: 1.4524 - acc: 0.350 - ETA: 0s - loss: 1.5004 - acc: 0.344 - ETA: 0s - loss: 1.4986 - acc: 0.353 - ETA: 0s - loss: 1.5001 - acc: 0.354 - 2s 12ms/step - loss: 1.5059 - acc: 0.3520 - val_loss: 1.3213 - val_acc: 0.5435\n",
      "Epoch 6/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3697 - acc: 0.520 - ETA: 1s - loss: 1.3550 - acc: 0.460 - ETA: 1s - loss: 1.4337 - acc: 0.400 - ETA: 0s - loss: 1.4352 - acc: 0.390 - ETA: 0s - loss: 1.4299 - acc: 0.376 - ETA: 0s - loss: 1.4441 - acc: 0.373 - ETA: 0s - loss: 1.4613 - acc: 0.360 - 2s 13ms/step - loss: 1.4643 - acc: 0.3520 - val_loss: 1.2656 - val_acc: 0.5435\n",
      "Epoch 7/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.5244 - acc: 0.400 - ETA: 1s - loss: 1.5291 - acc: 0.300 - ETA: 1s - loss: 1.4973 - acc: 0.333 - ETA: 0s - loss: 1.5025 - acc: 0.330 - ETA: 0s - loss: 1.4772 - acc: 0.336 - ETA: 0s - loss: 1.4681 - acc: 0.353 - ETA: 0s - loss: 1.4675 - acc: 0.360 - 2s 12ms/step - loss: 1.4712 - acc: 0.3575 - val_loss: 1.2594 - val_acc: 0.5435\n",
      "Epoch 8/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.2973 - acc: 0.520 - ETA: 1s - loss: 1.3340 - acc: 0.360 - ETA: 1s - loss: 1.3699 - acc: 0.346 - ETA: 0s - loss: 1.4295 - acc: 0.330 - ETA: 0s - loss: 1.4325 - acc: 0.352 - ETA: 0s - loss: 1.4213 - acc: 0.360 - ETA: 0s - loss: 1.4334 - acc: 0.365 - 2s 11ms/step - loss: 1.4330 - acc: 0.3687 - val_loss: 1.1990 - val_acc: 0.5435\n",
      "Epoch 9/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3841 - acc: 0.480 - ETA: 1s - loss: 1.3494 - acc: 0.380 - ETA: 1s - loss: 1.3046 - acc: 0.413 - ETA: 0s - loss: 1.3361 - acc: 0.400 - ETA: 0s - loss: 1.3535 - acc: 0.384 - ETA: 0s - loss: 1.3759 - acc: 0.360 - ETA: 0s - loss: 1.3916 - acc: 0.360 - 2s 11ms/step - loss: 1.3978 - acc: 0.3575 - val_loss: 1.3934 - val_acc: 0.6087\n",
      "Epoch 10/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3740 - acc: 0.560 - ETA: 1s - loss: 1.3782 - acc: 0.560 - ETA: 1s - loss: 1.3715 - acc: 0.480 - ETA: 0s - loss: 1.3872 - acc: 0.450 - ETA: 0s - loss: 1.4135 - acc: 0.448 - ETA: 0s - loss: 1.4147 - acc: 0.426 - ETA: 0s - loss: 1.4219 - acc: 0.405 - 2s 12ms/step - loss: 1.4317 - acc: 0.3966 - val_loss: 1.2812 - val_acc: 0.5870\n",
      "Epoch 11/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.6319 - acc: 0.160 - ETA: 1s - loss: 1.5161 - acc: 0.280 - ETA: 1s - loss: 1.5124 - acc: 0.373 - ETA: 0s - loss: 1.4962 - acc: 0.370 - ETA: 0s - loss: 1.4802 - acc: 0.368 - ETA: 0s - loss: 1.4778 - acc: 0.353 - ETA: 0s - loss: 1.4068 - acc: 0.388 - 2s 11ms/step - loss: 1.4093 - acc: 0.3855 - val_loss: 1.1392 - val_acc: 0.5435\n",
      "Epoch 12/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.7087 - acc: 0.280 - ETA: 1s - loss: 1.4267 - acc: 0.360 - ETA: 1s - loss: 1.4141 - acc: 0.360 - ETA: 0s - loss: 1.4057 - acc: 0.370 - ETA: 0s - loss: 1.4083 - acc: 0.368 - ETA: 0s - loss: 1.4058 - acc: 0.380 - ETA: 0s - loss: 1.4103 - acc: 0.365 - 2s 12ms/step - loss: 1.4008 - acc: 0.3687 - val_loss: 1.1438 - val_acc: 0.5435\n",
      "Epoch 13/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3421 - acc: 0.320 - ETA: 1s - loss: 1.5152 - acc: 0.300 - ETA: 1s - loss: 1.4509 - acc: 0.306 - ETA: 0s - loss: 1.4341 - acc: 0.350 - ETA: 0s - loss: 1.3758 - acc: 0.408 - ETA: 0s - loss: 1.3612 - acc: 0.440 - ETA: 0s - loss: 1.3626 - acc: 0.422 - 2s 13ms/step - loss: 1.3682 - acc: 0.4190 - val_loss: 1.1183 - val_acc: 0.5870\n",
      "Epoch 14/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.4332 - acc: 0.400 - ETA: 1s - loss: 1.3253 - acc: 0.440 - ETA: 1s - loss: 1.3170 - acc: 0.440 - ETA: 0s - loss: 1.3402 - acc: 0.390 - ETA: 0s - loss: 1.3210 - acc: 0.408 - ETA: 0s - loss: 1.3294 - acc: 0.400 - ETA: 0s - loss: 1.3107 - acc: 0.405 - 2s 13ms/step - loss: 1.3080 - acc: 0.4022 - val_loss: 1.0915 - val_acc: 0.6087\n",
      "Epoch 15/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3253 - acc: 0.440 - ETA: 1s - loss: 1.3252 - acc: 0.460 - ETA: 1s - loss: 1.2586 - acc: 0.480 - ETA: 0s - loss: 1.2890 - acc: 0.440 - ETA: 0s - loss: 1.2516 - acc: 0.456 - ETA: 0s - loss: 1.2539 - acc: 0.453 - ETA: 0s - loss: 1.2722 - acc: 0.462 - 2s 12ms/step - loss: 1.2720 - acc: 0.4581 - val_loss: 1.1036 - val_acc: 0.5870\n",
      "Epoch 16/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0945 - acc: 0.640 - ETA: 1s - loss: 1.0886 - acc: 0.620 - ETA: 1s - loss: 1.1532 - acc: 0.573 - ETA: 0s - loss: 1.1503 - acc: 0.580 - ETA: 0s - loss: 1.1399 - acc: 0.560 - ETA: 0s - loss: 1.2018 - acc: 0.513 - ETA: 0s - loss: 1.2301 - acc: 0.514 - 2s 11ms/step - loss: 1.2284 - acc: 0.5196 - val_loss: 1.0663 - val_acc: 0.5652\n",
      "Epoch 17/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1232 - acc: 0.480 - ETA: 1s - loss: 1.1781 - acc: 0.500 - ETA: 0s - loss: 1.1873 - acc: 0.480 - ETA: 0s - loss: 1.1830 - acc: 0.470 - ETA: 0s - loss: 1.1705 - acc: 0.496 - ETA: 0s - loss: 1.1608 - acc: 0.500 - ETA: 0s - loss: 1.1322 - acc: 0.525 - 2s 10ms/step - loss: 1.1391 - acc: 0.5251 - val_loss: 1.1570 - val_acc: 0.5435\n",
      "Epoch 18/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0823 - acc: 0.520 - ETA: 1s - loss: 1.1470 - acc: 0.520 - ETA: 0s - loss: 1.1181 - acc: 0.573 - ETA: 0s - loss: 1.0753 - acc: 0.560 - ETA: 0s - loss: 1.1289 - acc: 0.528 - ETA: 0s - loss: 1.0945 - acc: 0.540 - ETA: 0s - loss: 1.1290 - acc: 0.537 - 2s 10ms/step - loss: 1.1302 - acc: 0.5419 - val_loss: 1.0191 - val_acc: 0.5870\n",
      "Epoch 19/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.9492 - acc: 0.640 - ETA: 1s - loss: 1.0239 - acc: 0.580 - ETA: 0s - loss: 1.0598 - acc: 0.546 - ETA: 0s - loss: 0.9801 - acc: 0.610 - ETA: 0s - loss: 0.9605 - acc: 0.632 - ETA: 0s - loss: 1.0091 - acc: 0.606 - ETA: 0s - loss: 1.0127 - acc: 0.605 - 2s 11ms/step - loss: 1.0046 - acc: 0.6145 - val_loss: 0.9030 - val_acc: 0.6304\n",
      "Epoch 20/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0230 - acc: 0.520 - ETA: 1s - loss: 1.1749 - acc: 0.480 - ETA: 1s - loss: 1.1125 - acc: 0.506 - ETA: 0s - loss: 1.0297 - acc: 0.540 - ETA: 0s - loss: 1.0669 - acc: 0.536 - ETA: 0s - loss: 1.0309 - acc: 0.580 - ETA: 0s - loss: 0.9941 - acc: 0.582 - 2s 11ms/step - loss: 0.9887 - acc: 0.5866 - val_loss: 0.8039 - val_acc: 0.6739\n",
      "Epoch 21/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.8977 - acc: 0.640 - ETA: 1s - loss: 0.9142 - acc: 0.640 - ETA: 1s - loss: 0.9418 - acc: 0.640 - ETA: 0s - loss: 0.8662 - acc: 0.650 - ETA: 0s - loss: 0.8650 - acc: 0.664 - ETA: 0s - loss: 0.8794 - acc: 0.660 - ETA: 0s - loss: 0.8781 - acc: 0.662 - 2s 11ms/step - loss: 0.8658 - acc: 0.6704 - val_loss: 0.7958 - val_acc: 0.6522\n",
      "Epoch 22/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.6652 - acc: 0.720 - ETA: 1s - loss: 0.6926 - acc: 0.720 - ETA: 1s - loss: 0.7669 - acc: 0.733 - ETA: 0s - loss: 0.7921 - acc: 0.730 - ETA: 0s - loss: 0.8042 - acc: 0.696 - ETA: 0s - loss: 0.7977 - acc: 0.693 - ETA: 0s - loss: 0.7947 - acc: 0.697 - 2s 11ms/step - loss: 0.7860 - acc: 0.7039 - val_loss: 0.7580 - val_acc: 0.6957\n",
      "Epoch 23/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.8888 - acc: 0.720 - ETA: 1s - loss: 0.7693 - acc: 0.740 - ETA: 1s - loss: 0.6572 - acc: 0.760 - ETA: 0s - loss: 0.7075 - acc: 0.720 - ETA: 0s - loss: 0.6516 - acc: 0.760 - ETA: 0s - loss: 0.6549 - acc: 0.753 - ETA: 0s - loss: 0.6566 - acc: 0.742 - 2s 11ms/step - loss: 0.6574 - acc: 0.7374 - val_loss: 1.9538 - val_acc: 0.3261\n",
      "Epoch 24/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.8284 - acc: 0.360 - ETA: 1s - loss: 1.2957 - acc: 0.540 - ETA: 0s - loss: 1.0544 - acc: 0.586 - ETA: 0s - loss: 1.2522 - acc: 0.520 - ETA: 0s - loss: 1.1552 - acc: 0.552 - ETA: 0s - loss: 1.1289 - acc: 0.566 - ETA: 0s - loss: 1.1415 - acc: 0.571 - 2s 10ms/step - loss: 1.1285 - acc: 0.5810 - val_loss: 1.9224 - val_acc: 0.2609\n",
      "Epoch 25/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.7308 - acc: 0.400 - ETA: 1s - loss: 1.5108 - acc: 0.420 - ETA: 0s - loss: 1.4233 - acc: 0.466 - ETA: 0s - loss: 1.4090 - acc: 0.430 - ETA: 0s - loss: 1.3497 - acc: 0.440 - ETA: 0s - loss: 1.3185 - acc: 0.473 - ETA: 0s - loss: 1.2727 - acc: 0.491 - 2s 10ms/step - loss: 1.2574 - acc: 0.4972 - val_loss: 1.0643 - val_acc: 0.5652\n",
      "Epoch 26/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.8036 - acc: 0.760 - ETA: 1s - loss: 0.8181 - acc: 0.700 - ETA: 0s - loss: 0.8653 - acc: 0.653 - ETA: 0s - loss: 0.8374 - acc: 0.660 - ETA: 0s - loss: 0.9201 - acc: 0.640 - ETA: 0s - loss: 0.8995 - acc: 0.633 - ETA: 0s - loss: 0.8917 - acc: 0.640 - 2s 10ms/step - loss: 0.9033 - acc: 0.6369 - val_loss: 0.8526 - val_acc: 0.6957\n",
      "Epoch 27/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.7776 - acc: 0.720 - ETA: 1s - loss: 0.8175 - acc: 0.700 - ETA: 0s - loss: 0.8062 - acc: 0.733 - ETA: 0s - loss: 0.8479 - acc: 0.710 - ETA: 0s - loss: 0.8136 - acc: 0.712 - ETA: 0s - loss: 0.7689 - acc: 0.720 - ETA: 0s - loss: 0.7504 - acc: 0.720 - 2s 10ms/step - loss: 0.7566 - acc: 0.7207 - val_loss: 1.1237 - val_acc: 0.5217\n",
      "Epoch 28/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4622 - acc: 0.800 - ETA: 1s - loss: 0.6474 - acc: 0.720 - ETA: 1s - loss: 0.7613 - acc: 0.666 - ETA: 0s - loss: 0.8449 - acc: 0.650 - ETA: 0s - loss: 0.8565 - acc: 0.632 - ETA: 0s - loss: 0.8465 - acc: 0.646 - ETA: 0s - loss: 0.8994 - acc: 0.640 - 2s 11ms/step - loss: 0.8906 - acc: 0.6480 - val_loss: 2.1120 - val_acc: 0.3913\n",
      "Epoch 29/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0568 - acc: 0.560 - ETA: 1s - loss: 1.0923 - acc: 0.520 - ETA: 1s - loss: 0.9858 - acc: 0.573 - ETA: 0s - loss: 0.9064 - acc: 0.610 - ETA: 0s - loss: 0.8749 - acc: 0.640 - ETA: 0s - loss: 0.8217 - acc: 0.653 - ETA: 0s - loss: 0.7955 - acc: 0.674 - 2s 11ms/step - loss: 0.7967 - acc: 0.6704 - val_loss: 0.7741 - val_acc: 0.6957\n",
      "Epoch 30/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.6194 - acc: 0.680 - ETA: 1s - loss: 0.6197 - acc: 0.740 - ETA: 1s - loss: 0.7256 - acc: 0.720 - ETA: 0s - loss: 0.8133 - acc: 0.700 - ETA: 0s - loss: 0.7928 - acc: 0.704 - ETA: 0s - loss: 0.7511 - acc: 0.713 - ETA: 0s - loss: 0.6977 - acc: 0.748 - 2s 11ms/step - loss: 0.7004 - acc: 0.7430 - val_loss: 0.7800 - val_acc: 0.7174\n",
      "Epoch 31/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.3982 - acc: 0.920 - ETA: 1s - loss: 0.4306 - acc: 0.880 - ETA: 1s - loss: 0.4880 - acc: 0.866 - ETA: 0s - loss: 0.4999 - acc: 0.850 - ETA: 0s - loss: 0.5124 - acc: 0.824 - ETA: 0s - loss: 0.4913 - acc: 0.840 - ETA: 0s - loss: 0.5175 - acc: 0.828 - 2s 11ms/step - loss: 0.5212 - acc: 0.8268 - val_loss: 0.8550 - val_acc: 0.6739\n",
      "Epoch 32/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.7944 - acc: 0.680 - ETA: 1s - loss: 0.6644 - acc: 0.740 - ETA: 1s - loss: 0.5213 - acc: 0.800 - ETA: 0s - loss: 0.5517 - acc: 0.800 - ETA: 0s - loss: 0.5040 - acc: 0.824 - ETA: 0s - loss: 0.4754 - acc: 0.826 - ETA: 0s - loss: 0.4548 - acc: 0.840 - 2s 10ms/step - loss: 0.4555 - acc: 0.8324 - val_loss: 0.8811 - val_acc: 0.7391\n",
      "Epoch 33/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.3003 - acc: 0.880 - ETA: 1s - loss: 0.3711 - acc: 0.840 - ETA: 0s - loss: 0.4023 - acc: 0.853 - ETA: 0s - loss: 0.4806 - acc: 0.830 - ETA: 0s - loss: 0.5249 - acc: 0.808 - ETA: 0s - loss: 0.5044 - acc: 0.820 - ETA: 0s - loss: 0.4872 - acc: 0.822 - 2s 10ms/step - loss: 0.4814 - acc: 0.8268 - val_loss: 0.7660 - val_acc: 0.6957\n",
      "Epoch 34/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4712 - acc: 0.800 - ETA: 1s - loss: 0.3794 - acc: 0.860 - ETA: 0s - loss: 0.3371 - acc: 0.893 - ETA: 0s - loss: 0.3504 - acc: 0.890 - ETA: 0s - loss: 0.3330 - acc: 0.904 - ETA: 0s - loss: 0.3662 - acc: 0.886 - ETA: 0s - loss: 0.3836 - acc: 0.868 - 2s 10ms/step - loss: 0.3787 - acc: 0.8715 - val_loss: 1.0014 - val_acc: 0.6522\n",
      "Epoch 35/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2161 - acc: 0.960 - ETA: 1s - loss: 0.2624 - acc: 0.900 - ETA: 0s - loss: 0.3045 - acc: 0.866 - ETA: 0s - loss: 0.3541 - acc: 0.850 - ETA: 0s - loss: 0.3605 - acc: 0.856 - ETA: 0s - loss: 0.3631 - acc: 0.866 - ETA: 0s - loss: 0.3332 - acc: 0.885 - 2s 10ms/step - loss: 0.3385 - acc: 0.8827 - val_loss: 1.0419 - val_acc: 0.5870\n",
      "Epoch 36/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4139 - acc: 0.880 - ETA: 1s - loss: 0.3760 - acc: 0.880 - ETA: 0s - loss: 0.3453 - acc: 0.880 - ETA: 0s - loss: 0.3056 - acc: 0.890 - ETA: 0s - loss: 0.2974 - acc: 0.896 - ETA: 0s - loss: 0.2952 - acc: 0.893 - ETA: 0s - loss: 0.3201 - acc: 0.880 - 2s 10ms/step - loss: 0.3226 - acc: 0.8771 - val_loss: 0.9365 - val_acc: 0.6522\n",
      "Epoch 37/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.3816 - acc: 0.840 - ETA: 1s - loss: 0.3915 - acc: 0.860 - ETA: 1s - loss: 0.3095 - acc: 0.906 - ETA: 0s - loss: 0.2869 - acc: 0.910 - ETA: 0s - loss: 0.2842 - acc: 0.904 - ETA: 0s - loss: 0.2935 - acc: 0.893 - ETA: 0s - loss: 0.2618 - acc: 0.908 - 2s 11ms/step - loss: 0.2601 - acc: 0.9050 - val_loss: 0.9590 - val_acc: 0.7609\n",
      "Epoch 38/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.1979 - acc: 0.920 - ETA: 1s - loss: 0.2820 - acc: 0.880 - ETA: 1s - loss: 0.2881 - acc: 0.880 - ETA: 0s - loss: 0.2460 - acc: 0.900 - ETA: 0s - loss: 0.2297 - acc: 0.912 - ETA: 0s - loss: 0.2407 - acc: 0.906 - ETA: 0s - loss: 0.2511 - acc: 0.902 - 2s 11ms/step - loss: 0.2478 - acc: 0.9050 - val_loss: 0.9677 - val_acc: 0.7609\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - ETA: 1s - loss: 0.1671 - acc: 0.960 - ETA: 1s - loss: 0.1503 - acc: 0.940 - ETA: 1s - loss: 0.1911 - acc: 0.933 - ETA: 0s - loss: 0.1972 - acc: 0.930 - ETA: 0s - loss: 0.2055 - acc: 0.920 - ETA: 0s - loss: 0.2011 - acc: 0.920 - ETA: 0s - loss: 0.2038 - acc: 0.920 - 2s 11ms/step - loss: 0.2175 - acc: 0.9050 - val_loss: 0.9223 - val_acc: 0.6304\n",
      "Epoch 40/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0861 - acc: 0.960 - ETA: 1s - loss: 0.1631 - acc: 0.940 - ETA: 1s - loss: 0.3155 - acc: 0.893 - ETA: 0s - loss: 0.4338 - acc: 0.860 - ETA: 0s - loss: 0.4033 - acc: 0.872 - ETA: 0s - loss: 0.3857 - acc: 0.873 - ETA: 0s - loss: 0.3762 - acc: 0.868 - 2s 10ms/step - loss: 0.4056 - acc: 0.8603 - val_loss: 1.0026 - val_acc: 0.7174\n",
      "Epoch 41/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2297 - acc: 0.960 - ETA: 1s - loss: 0.3280 - acc: 0.880 - ETA: 0s - loss: 0.4492 - acc: 0.840 - ETA: 0s - loss: 0.5162 - acc: 0.810 - ETA: 0s - loss: 0.4599 - acc: 0.840 - ETA: 0s - loss: 0.4408 - acc: 0.853 - ETA: 0s - loss: 0.4242 - acc: 0.857 - 2s 10ms/step - loss: 0.4279 - acc: 0.8547 - val_loss: 1.0842 - val_acc: 0.6087\n",
      "Epoch 42/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.5632 - acc: 0.720 - ETA: 1s - loss: 0.4764 - acc: 0.800 - ETA: 0s - loss: 0.4469 - acc: 0.813 - ETA: 0s - loss: 0.4267 - acc: 0.810 - ETA: 0s - loss: 0.4057 - acc: 0.824 - ETA: 0s - loss: 0.3944 - acc: 0.826 - ETA: 0s - loss: 0.3887 - acc: 0.834 - 2s 10ms/step - loss: 0.3835 - acc: 0.8380 - val_loss: 1.2249 - val_acc: 0.6304\n",
      "Epoch 43/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2135 - acc: 0.960 - ETA: 1s - loss: 0.2294 - acc: 0.940 - ETA: 0s - loss: 0.2139 - acc: 0.933 - ETA: 0s - loss: 0.1995 - acc: 0.940 - ETA: 0s - loss: 0.2392 - acc: 0.920 - ETA: 0s - loss: 0.2158 - acc: 0.933 - ETA: 0s - loss: 0.1969 - acc: 0.942 - 2s 10ms/step - loss: 0.2001 - acc: 0.9385 - val_loss: 1.2518 - val_acc: 0.6522\n",
      "Epoch 44/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.1218 - acc: 0.960 - ETA: 1s - loss: 0.1320 - acc: 0.960 - ETA: 0s - loss: 0.1543 - acc: 0.960 - ETA: 0s - loss: 0.1702 - acc: 0.970 - ETA: 0s - loss: 0.1774 - acc: 0.952 - ETA: 0s - loss: 0.1512 - acc: 0.960 - ETA: 0s - loss: 0.1666 - acc: 0.960 - 2s 10ms/step - loss: 0.1633 - acc: 0.9609 - val_loss: 1.1940 - val_acc: 0.5870\n",
      "Epoch 45/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.1400 - acc: 0.960 - ETA: 1s - loss: 0.1417 - acc: 0.960 - ETA: 1s - loss: 0.1915 - acc: 0.946 - ETA: 0s - loss: 0.1634 - acc: 0.960 - ETA: 0s - loss: 0.1404 - acc: 0.968 - ETA: 0s - loss: 0.1264 - acc: 0.973 - ETA: 0s - loss: 0.1398 - acc: 0.960 - 2s 11ms/step - loss: 0.1383 - acc: 0.9609 - val_loss: 1.2850 - val_acc: 0.7174\n",
      "Epoch 46/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0405 - acc: 1.000 - ETA: 1s - loss: 0.0456 - acc: 1.000 - ETA: 1s - loss: 0.0904 - acc: 0.973 - ETA: 0s - loss: 0.0811 - acc: 0.980 - ETA: 0s - loss: 0.0687 - acc: 0.984 - ETA: 0s - loss: 0.0781 - acc: 0.980 - ETA: 0s - loss: 0.0796 - acc: 0.982 - 2s 11ms/step - loss: 0.0778 - acc: 0.9832 - val_loss: 1.3475 - val_acc: 0.6087\n",
      "Epoch 47/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.1960 - acc: 0.960 - ETA: 1s - loss: 0.1720 - acc: 0.960 - ETA: 1s - loss: 0.1591 - acc: 0.960 - ETA: 0s - loss: 0.1439 - acc: 0.960 - ETA: 0s - loss: 0.1243 - acc: 0.968 - ETA: 0s - loss: 0.1133 - acc: 0.973 - ETA: 0s - loss: 0.1013 - acc: 0.977 - 2s 11ms/step - loss: 0.0991 - acc: 0.9777 - val_loss: 1.2833 - val_acc: 0.7391\n",
      "Epoch 48/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0387 - acc: 1.000 - ETA: 1s - loss: 0.0315 - acc: 1.000 - ETA: 1s - loss: 0.0272 - acc: 1.000 - ETA: 0s - loss: 0.0748 - acc: 0.980 - ETA: 0s - loss: 0.0709 - acc: 0.984 - ETA: 0s - loss: 0.0638 - acc: 0.986 - ETA: 0s - loss: 0.0564 - acc: 0.988 - 2s 11ms/step - loss: 0.0561 - acc: 0.9888 - val_loss: 1.3418 - val_acc: 0.6522\n",
      "Epoch 49/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0129 - acc: 1.000 - ETA: 1s - loss: 0.0247 - acc: 1.000 - ETA: 1s - loss: 0.0343 - acc: 1.000 - ETA: 0s - loss: 0.0295 - acc: 1.000 - ETA: 0s - loss: 0.0265 - acc: 1.000 - ETA: 0s - loss: 0.0287 - acc: 1.000 - ETA: 0s - loss: 0.0252 - acc: 1.000 - 2s 11ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 1.4480 - val_acc: 0.6739\n",
      "Epoch 50/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0056 - acc: 1.000 - ETA: 1s - loss: 0.0047 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 1.000 - ETA: 0s - loss: 0.0058 - acc: 1.000 - ETA: 0s - loss: 0.0112 - acc: 1.000 - ETA: 0s - loss: 0.0140 - acc: 1.000 - ETA: 0s - loss: 0.0145 - acc: 1.000 - 2s 10ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.5014 - val_acc: 0.7391\n",
      "K-Fold-1\n",
      "=========================================\n",
      "Test loss: 1.501426849676215\n",
      "Test accuracy: 0.739130437374115\n",
      "=========================================\n",
      "\n",
      "Iterasi ke-2\n",
      "Train : [  0   1   3   4   6   7   8   9  10  11  12  13  14  15  16  17  19  20\n",
      "  21  22  23  24  26  27  28  30  31  32  33  35  36  39  40  42  44  45\n",
      "  46  48  49  50  51  52  54  55  58  61  63  65  67  69  70  71  72  74\n",
      "  75  76  77  78  79  81  82  83  84  85  86  87  88  89  90  91  93  95\n",
      "  96  97  98  99 100 102 103 105 107 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 130 132 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148 149 151 152 153 155 156 157 158 159\n",
      " 160 161 162 163 164 166 167 168 170 171 172 173 174 175 177 178 179 180\n",
      " 182 183 184 185 186 187 188 189 191 193 194 195 196 197 198 199 200 205\n",
      " 206 207 208 209 210 211 212 213 214 215 216 217 218 221 222 223 224]\n",
      "Test : [  2   5  18  25  29  34  37  38  41  43  47  53  56  57  59  60  62  64\n",
      "  66  68  73  80  92  94 101 104 106 108 127 128 129 131 150 154 165 169\n",
      " 176 181 190 192 201 202 203 204 219 220]\n",
      "Train on 179 samples, validate on 46 samples\n",
      "Epoch 1/50\n",
      "179/179 [==============================] - ETA: 11s - loss: 1.7861 - acc: 0.36 - ETA: 5s - loss: 1.9096 - acc: 0.4000 - ETA: 3s - loss: 2.0211 - acc: 0.373 - ETA: 2s - loss: 2.0017 - acc: 0.320 - ETA: 1s - loss: 1.9134 - acc: 0.320 - ETA: 0s - loss: 1.8522 - acc: 0.313 - ETA: 0s - loss: 1.7542 - acc: 0.337 - 4s 22ms/step - loss: 1.7513 - acc: 0.3408 - val_loss: 1.7357 - val_acc: 0.3043\n",
      "Epoch 2/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.6425 - acc: 0.440 - ETA: 1s - loss: 1.5597 - acc: 0.400 - ETA: 1s - loss: 1.6106 - acc: 0.333 - ETA: 0s - loss: 1.6011 - acc: 0.330 - ETA: 0s - loss: 1.6098 - acc: 0.304 - ETA: 0s - loss: 1.5751 - acc: 0.293 - ETA: 0s - loss: 1.5651 - acc: 0.308 - 2s 12ms/step - loss: 1.5483 - acc: 0.3128 - val_loss: 1.8521 - val_acc: 0.3043\n",
      "Epoch 3/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.4937 - acc: 0.440 - ETA: 1s - loss: 1.4478 - acc: 0.440 - ETA: 1s - loss: 1.4547 - acc: 0.426 - ETA: 0s - loss: 1.4209 - acc: 0.450 - ETA: 0s - loss: 1.4517 - acc: 0.424 - ETA: 0s - loss: 1.4524 - acc: 0.406 - ETA: 0s - loss: 1.4482 - acc: 0.400 - 2s 12ms/step - loss: 1.4405 - acc: 0.4022 - val_loss: 1.5459 - val_acc: 0.3043\n",
      "Epoch 4/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3330 - acc: 0.360 - ETA: 1s - loss: 1.3104 - acc: 0.440 - ETA: 1s - loss: 1.3266 - acc: 0.413 - ETA: 0s - loss: 1.3548 - acc: 0.420 - ETA: 0s - loss: 1.3499 - acc: 0.432 - ETA: 0s - loss: 1.3473 - acc: 0.440 - ETA: 0s - loss: 1.4382 - acc: 0.422 - 2s 12ms/step - loss: 1.4310 - acc: 0.4246 - val_loss: 1.5582 - val_acc: 0.3043\n",
      "Epoch 5/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.5002 - acc: 0.280 - ETA: 1s - loss: 1.4684 - acc: 0.380 - ETA: 1s - loss: 1.4621 - acc: 0.373 - ETA: 0s - loss: 1.4629 - acc: 0.330 - ETA: 0s - loss: 1.4247 - acc: 0.328 - ETA: 0s - loss: 1.4136 - acc: 0.326 - ETA: 0s - loss: 1.4038 - acc: 0.337 - 2s 11ms/step - loss: 1.4039 - acc: 0.3352 - val_loss: 1.5368 - val_acc: 0.3043\n",
      "Epoch 6/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.4301 - acc: 0.280 - ETA: 1s - loss: 1.3271 - acc: 0.420 - ETA: 0s - loss: 1.3126 - acc: 0.440 - ETA: 0s - loss: 1.3392 - acc: 0.440 - ETA: 0s - loss: 1.3062 - acc: 0.440 - ETA: 0s - loss: 1.3170 - acc: 0.426 - ETA: 0s - loss: 1.3214 - acc: 0.428 - 2s 10ms/step - loss: 1.3093 - acc: 0.4358 - val_loss: 2.8793 - val_acc: 0.3043\n",
      "Epoch 7/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 2.3626 - acc: 0.440 - ETA: 1s - loss: 1.7246 - acc: 0.500 - ETA: 0s - loss: 1.6275 - acc: 0.440 - ETA: 0s - loss: 1.5843 - acc: 0.430 - ETA: 0s - loss: 1.5490 - acc: 0.448 - ETA: 0s - loss: 1.5267 - acc: 0.473 - ETA: 0s - loss: 1.5093 - acc: 0.474 - 2s 10ms/step - loss: 1.5069 - acc: 0.4749 - val_loss: 1.5238 - val_acc: 0.3043\n",
      "Epoch 8/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0320 - acc: 0.600 - ETA: 1s - loss: 1.2729 - acc: 0.500 - ETA: 0s - loss: 1.2893 - acc: 0.493 - ETA: 0s - loss: 1.3336 - acc: 0.450 - ETA: 0s - loss: 1.3499 - acc: 0.440 - ETA: 0s - loss: 1.3583 - acc: 0.440 - ETA: 0s - loss: 1.3763 - acc: 0.434 - 2s 11ms/step - loss: 1.3824 - acc: 0.4302 - val_loss: 1.5199 - val_acc: 0.3261\n",
      "Epoch 9/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.4447 - acc: 0.480 - ETA: 1s - loss: 1.3905 - acc: 0.540 - ETA: 1s - loss: 1.3705 - acc: 0.533 - ETA: 0s - loss: 1.2953 - acc: 0.530 - ETA: 0s - loss: 1.3919 - acc: 0.464 - ETA: 0s - loss: 1.3948 - acc: 0.453 - ETA: 0s - loss: 1.4002 - acc: 0.440 - 3s 14ms/step - loss: 1.3996 - acc: 0.4413 - val_loss: 1.5065 - val_acc: 0.3913\n",
      "Epoch 10/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3701 - acc: 0.480 - ETA: 1s - loss: 1.3637 - acc: 0.500 - ETA: 1s - loss: 1.3848 - acc: 0.453 - ETA: 0s - loss: 1.3780 - acc: 0.500 - ETA: 0s - loss: 1.3716 - acc: 0.480 - ETA: 0s - loss: 1.3410 - acc: 0.480 - ETA: 0s - loss: 1.3409 - acc: 0.474 - 2s 13ms/step - loss: 1.3300 - acc: 0.4804 - val_loss: 1.6784 - val_acc: 0.3043\n",
      "Epoch 11/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.2947 - acc: 0.480 - ETA: 1s - loss: 1.4667 - acc: 0.320 - ETA: 1s - loss: 1.3807 - acc: 0.400 - ETA: 0s - loss: 1.3701 - acc: 0.430 - ETA: 0s - loss: 1.3522 - acc: 0.456 - ETA: 0s - loss: 1.3530 - acc: 0.473 - ETA: 0s - loss: 1.3598 - acc: 0.480 - 2s 12ms/step - loss: 1.3625 - acc: 0.4804 - val_loss: 1.4974 - val_acc: 0.4130\n",
      "Epoch 12/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3811 - acc: 0.360 - ETA: 1s - loss: 1.3202 - acc: 0.440 - ETA: 1s - loss: 1.2912 - acc: 0.453 - ETA: 0s - loss: 1.3573 - acc: 0.440 - ETA: 0s - loss: 1.3108 - acc: 0.488 - ETA: 0s - loss: 1.3072 - acc: 0.473 - ETA: 0s - loss: 1.3075 - acc: 0.491 - 2s 11ms/step - loss: 1.3089 - acc: 0.4860 - val_loss: 1.4817 - val_acc: 0.3696\n",
      "Epoch 13/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.2477 - acc: 0.640 - ETA: 1s - loss: 1.3385 - acc: 0.520 - ETA: 1s - loss: 1.2938 - acc: 0.506 - ETA: 0s - loss: 1.3401 - acc: 0.470 - ETA: 0s - loss: 1.3141 - acc: 0.472 - ETA: 0s - loss: 1.3156 - acc: 0.453 - ETA: 0s - loss: 1.2866 - acc: 0.474 - 2s 10ms/step - loss: 1.2885 - acc: 0.4749 - val_loss: 1.4468 - val_acc: 0.3913\n",
      "Epoch 14/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1791 - acc: 0.440 - ETA: 1s - loss: 1.1344 - acc: 0.480 - ETA: 0s - loss: 1.2007 - acc: 0.480 - ETA: 0s - loss: 1.1933 - acc: 0.490 - ETA: 0s - loss: 1.2047 - acc: 0.488 - ETA: 0s - loss: 1.2415 - acc: 0.466 - ETA: 0s - loss: 1.2094 - acc: 0.502 - 2s 10ms/step - loss: 1.2075 - acc: 0.5028 - val_loss: 1.4697 - val_acc: 0.3478\n",
      "Epoch 15/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1952 - acc: 0.400 - ETA: 1s - loss: 1.1352 - acc: 0.520 - ETA: 0s - loss: 1.1075 - acc: 0.573 - ETA: 0s - loss: 1.1789 - acc: 0.560 - ETA: 0s - loss: 1.2695 - acc: 0.512 - ETA: 0s - loss: 1.2638 - acc: 0.520 - ETA: 0s - loss: 1.2669 - acc: 0.502 - 2s 10ms/step - loss: 1.2703 - acc: 0.4972 - val_loss: 1.4626 - val_acc: 0.4348\n",
      "Epoch 16/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3925 - acc: 0.480 - ETA: 1s - loss: 1.3692 - acc: 0.440 - ETA: 0s - loss: 1.2936 - acc: 0.480 - ETA: 0s - loss: 1.2877 - acc: 0.460 - ETA: 0s - loss: 1.2232 - acc: 0.512 - ETA: 0s - loss: 1.2582 - acc: 0.486 - ETA: 0s - loss: 1.2306 - acc: 0.497 - 2s 10ms/step - loss: 1.2438 - acc: 0.4916 - val_loss: 1.4309 - val_acc: 0.3696\n",
      "Epoch 17/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1687 - acc: 0.520 - ETA: 1s - loss: 1.2229 - acc: 0.560 - ETA: 1s - loss: 1.2503 - acc: 0.560 - ETA: 0s - loss: 1.2596 - acc: 0.540 - ETA: 0s - loss: 1.2809 - acc: 0.512 - ETA: 0s - loss: 1.2696 - acc: 0.500 - ETA: 0s - loss: 1.2719 - acc: 0.508 - 2s 11ms/step - loss: 1.2747 - acc: 0.5028 - val_loss: 1.7348 - val_acc: 0.3043\n",
      "Epoch 18/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0792 - acc: 0.480 - ETA: 1s - loss: 1.3738 - acc: 0.460 - ETA: 1s - loss: 1.2984 - acc: 0.466 - ETA: 0s - loss: 1.2431 - acc: 0.460 - ETA: 0s - loss: 1.2556 - acc: 0.472 - ETA: 0s - loss: 1.2325 - acc: 0.486 - ETA: 0s - loss: 1.2469 - acc: 0.491 - 2s 11ms/step - loss: 1.2451 - acc: 0.4972 - val_loss: 1.4288 - val_acc: 0.4348\n",
      "Epoch 19/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1174 - acc: 0.560 - ETA: 1s - loss: 1.3017 - acc: 0.480 - ETA: 1s - loss: 1.2887 - acc: 0.493 - ETA: 0s - loss: 1.2416 - acc: 0.530 - ETA: 0s - loss: 1.2008 - acc: 0.536 - ETA: 0s - loss: 1.1980 - acc: 0.520 - ETA: 0s - loss: 1.1692 - acc: 0.531 - 2s 11ms/step - loss: 1.1616 - acc: 0.5419 - val_loss: 1.4293 - val_acc: 0.3478\n",
      "Epoch 20/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3054 - acc: 0.480 - ETA: 1s - loss: 1.0813 - acc: 0.580 - ETA: 1s - loss: 1.0999 - acc: 0.546 - ETA: 0s - loss: 1.0937 - acc: 0.550 - ETA: 0s - loss: 1.1087 - acc: 0.544 - ETA: 0s - loss: 1.1074 - acc: 0.540 - ETA: 0s - loss: 1.1133 - acc: 0.548 - 2s 11ms/step - loss: 1.1091 - acc: 0.5419 - val_loss: 1.3986 - val_acc: 0.4130\n",
      "Epoch 21/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.3441 - acc: 0.440 - ETA: 1s - loss: 1.1299 - acc: 0.540 - ETA: 0s - loss: 1.0267 - acc: 0.586 - ETA: 0s - loss: 0.9895 - acc: 0.590 - ETA: 0s - loss: 1.0124 - acc: 0.576 - ETA: 0s - loss: 1.0567 - acc: 0.573 - ETA: 0s - loss: 1.0324 - acc: 0.577 - 2s 10ms/step - loss: 1.0391 - acc: 0.5754 - val_loss: 1.3296 - val_acc: 0.4130\n",
      "Epoch 22/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.1122 - acc: 0.640 - ETA: 1s - loss: 1.1242 - acc: 0.500 - ETA: 0s - loss: 1.1224 - acc: 0.520 - ETA: 0s - loss: 1.0979 - acc: 0.540 - ETA: 0s - loss: 1.1190 - acc: 0.512 - ETA: 0s - loss: 1.0879 - acc: 0.540 - ETA: 0s - loss: 1.1151 - acc: 0.531 - 2s 10ms/step - loss: 1.1082 - acc: 0.5307 - val_loss: 1.3919 - val_acc: 0.3913\n",
      "Epoch 23/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.0321 - acc: 0.560 - ETA: 1s - loss: 0.9727 - acc: 0.640 - ETA: 0s - loss: 1.0135 - acc: 0.613 - ETA: 0s - loss: 0.9342 - acc: 0.660 - ETA: 0s - loss: 0.9215 - acc: 0.656 - ETA: 0s - loss: 0.9574 - acc: 0.640 - ETA: 0s - loss: 0.9604 - acc: 0.634 - 2s 10ms/step - loss: 0.9587 - acc: 0.6369 - val_loss: 1.2433 - val_acc: 0.3913\n",
      "Epoch 24/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.6512 - acc: 0.760 - ETA: 1s - loss: 0.8915 - acc: 0.660 - ETA: 0s - loss: 0.8969 - acc: 0.680 - ETA: 0s - loss: 0.9146 - acc: 0.660 - ETA: 0s - loss: 0.9413 - acc: 0.616 - ETA: 0s - loss: 0.9626 - acc: 0.613 - ETA: 0s - loss: 0.9314 - acc: 0.634 - 2s 10ms/step - loss: 0.9175 - acc: 0.6425 - val_loss: 1.4490 - val_acc: 0.4130\n",
      "Epoch 25/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.7456 - acc: 0.720 - ETA: 1s - loss: 0.8550 - acc: 0.620 - ETA: 1s - loss: 0.8632 - acc: 0.613 - ETA: 0s - loss: 0.8356 - acc: 0.660 - ETA: 0s - loss: 0.8471 - acc: 0.640 - ETA: 0s - loss: 0.8374 - acc: 0.640 - ETA: 0s - loss: 0.8990 - acc: 0.634 - 2s 11ms/step - loss: 0.8841 - acc: 0.6425 - val_loss: 1.2817 - val_acc: 0.5000\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - ETA: 1s - loss: 0.7880 - acc: 0.680 - ETA: 1s - loss: 0.8151 - acc: 0.700 - ETA: 1s - loss: 0.7884 - acc: 0.680 - ETA: 0s - loss: 0.7121 - acc: 0.720 - ETA: 0s - loss: 0.8289 - acc: 0.704 - ETA: 0s - loss: 0.9195 - acc: 0.660 - ETA: 0s - loss: 0.8579 - acc: 0.680 - 2s 11ms/step - loss: 0.8540 - acc: 0.6816 - val_loss: 1.2025 - val_acc: 0.4565\n",
      "Epoch 27/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 1.2128 - acc: 0.520 - ETA: 1s - loss: 1.1016 - acc: 0.600 - ETA: 1s - loss: 1.0556 - acc: 0.600 - ETA: 0s - loss: 0.9967 - acc: 0.610 - ETA: 0s - loss: 0.9958 - acc: 0.608 - ETA: 0s - loss: 0.9375 - acc: 0.626 - ETA: 0s - loss: 0.9262 - acc: 0.634 - 2s 11ms/step - loss: 0.9259 - acc: 0.6313 - val_loss: 1.6039 - val_acc: 0.4348\n",
      "Epoch 28/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.8498 - acc: 0.680 - ETA: 1s - loss: 0.7634 - acc: 0.700 - ETA: 1s - loss: 0.7722 - acc: 0.693 - ETA: 0s - loss: 0.7744 - acc: 0.710 - ETA: 0s - loss: 0.8226 - acc: 0.680 - ETA: 0s - loss: 0.8080 - acc: 0.693 - ETA: 0s - loss: 0.7975 - acc: 0.697 - 2s 11ms/step - loss: 0.7929 - acc: 0.6983 - val_loss: 1.2348 - val_acc: 0.4783\n",
      "Epoch 29/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.5142 - acc: 0.760 - ETA: 1s - loss: 0.5538 - acc: 0.760 - ETA: 1s - loss: 0.5856 - acc: 0.760 - ETA: 0s - loss: 0.8992 - acc: 0.700 - ETA: 0s - loss: 0.8614 - acc: 0.688 - ETA: 0s - loss: 0.8310 - acc: 0.706 - ETA: 0s - loss: 0.7899 - acc: 0.720 - 2s 11ms/step - loss: 0.8074 - acc: 0.7095 - val_loss: 1.2231 - val_acc: 0.5435\n",
      "Epoch 30/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.8842 - acc: 0.600 - ETA: 1s - loss: 0.9808 - acc: 0.620 - ETA: 0s - loss: 0.9673 - acc: 0.613 - ETA: 0s - loss: 0.8871 - acc: 0.640 - ETA: 0s - loss: 0.8492 - acc: 0.640 - ETA: 0s - loss: 0.8159 - acc: 0.653 - ETA: 0s - loss: 0.8420 - acc: 0.640 - 2s 10ms/step - loss: 0.8481 - acc: 0.6425 - val_loss: 1.1425 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.6490 - acc: 0.800 - ETA: 1s - loss: 0.7134 - acc: 0.720 - ETA: 0s - loss: 0.6955 - acc: 0.733 - ETA: 0s - loss: 0.7477 - acc: 0.690 - ETA: 0s - loss: 0.7228 - acc: 0.688 - ETA: 0s - loss: 0.6642 - acc: 0.726 - ETA: 0s - loss: 0.6892 - acc: 0.720 - 2s 10ms/step - loss: 0.6819 - acc: 0.7263 - val_loss: 1.1363 - val_acc: 0.5870\n",
      "Epoch 32/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.7525 - acc: 0.760 - ETA: 1s - loss: 0.7409 - acc: 0.720 - ETA: 1s - loss: 0.6833 - acc: 0.733 - ETA: 0s - loss: 0.6161 - acc: 0.760 - ETA: 0s - loss: 0.6496 - acc: 0.752 - ETA: 0s - loss: 0.6243 - acc: 0.746 - ETA: 0s - loss: 0.6575 - acc: 0.737 - 2s 10ms/step - loss: 0.6510 - acc: 0.7374 - val_loss: 1.3008 - val_acc: 0.5435\n",
      "Epoch 33/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.6270 - acc: 0.720 - ETA: 1s - loss: 0.6137 - acc: 0.780 - ETA: 0s - loss: 0.6053 - acc: 0.773 - ETA: 0s - loss: 0.5867 - acc: 0.770 - ETA: 0s - loss: 0.5494 - acc: 0.792 - ETA: 0s - loss: 0.5306 - acc: 0.793 - ETA: 0s - loss: 0.5195 - acc: 0.800 - 2s 11ms/step - loss: 0.5343 - acc: 0.7933 - val_loss: 1.4704 - val_acc: 0.5217\n",
      "Epoch 34/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.5744 - acc: 0.760 - ETA: 1s - loss: 0.4577 - acc: 0.820 - ETA: 1s - loss: 0.4228 - acc: 0.840 - ETA: 0s - loss: 0.4500 - acc: 0.840 - ETA: 0s - loss: 0.4753 - acc: 0.816 - ETA: 0s - loss: 0.4723 - acc: 0.826 - ETA: 0s - loss: 0.4613 - acc: 0.834 - 2s 11ms/step - loss: 0.4754 - acc: 0.8212 - val_loss: 1.2583 - val_acc: 0.5652\n",
      "Epoch 35/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.5129 - acc: 0.840 - ETA: 1s - loss: 0.6196 - acc: 0.760 - ETA: 1s - loss: 0.7846 - acc: 0.706 - ETA: 0s - loss: 0.6938 - acc: 0.730 - ETA: 0s - loss: 0.6936 - acc: 0.720 - ETA: 0s - loss: 0.6783 - acc: 0.733 - ETA: 0s - loss: 0.6885 - acc: 0.731 - 2s 11ms/step - loss: 0.6739 - acc: 0.7374 - val_loss: 1.1937 - val_acc: 0.5870\n",
      "Epoch 36/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.5143 - acc: 0.800 - ETA: 1s - loss: 0.5489 - acc: 0.780 - ETA: 1s - loss: 0.5020 - acc: 0.813 - ETA: 0s - loss: 0.5318 - acc: 0.800 - ETA: 0s - loss: 0.5153 - acc: 0.808 - ETA: 0s - loss: 0.4917 - acc: 0.820 - ETA: 0s - loss: 0.4786 - acc: 0.817 - 2s 11ms/step - loss: 0.5087 - acc: 0.8045 - val_loss: 1.3882 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.7598 - acc: 0.720 - ETA: 1s - loss: 0.6008 - acc: 0.800 - ETA: 1s - loss: 0.5961 - acc: 0.773 - ETA: 0s - loss: 0.5751 - acc: 0.780 - ETA: 0s - loss: 0.5558 - acc: 0.800 - ETA: 0s - loss: 0.5581 - acc: 0.793 - ETA: 0s - loss: 0.5468 - acc: 0.794 - 2s 11ms/step - loss: 0.5571 - acc: 0.7877 - val_loss: 1.3103 - val_acc: 0.5435\n",
      "Epoch 38/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4760 - acc: 0.760 - ETA: 1s - loss: 0.4922 - acc: 0.800 - ETA: 0s - loss: 0.4632 - acc: 0.813 - ETA: 0s - loss: 0.5045 - acc: 0.790 - ETA: 0s - loss: 0.4877 - acc: 0.808 - ETA: 0s - loss: 0.4597 - acc: 0.813 - ETA: 0s - loss: 0.4650 - acc: 0.805 - 2s 10ms/step - loss: 0.4572 - acc: 0.8101 - val_loss: 1.3278 - val_acc: 0.5217\n",
      "Epoch 39/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.3473 - acc: 0.840 - ETA: 1s - loss: 0.2497 - acc: 0.900 - ETA: 0s - loss: 0.2988 - acc: 0.880 - ETA: 0s - loss: 0.3914 - acc: 0.840 - ETA: 0s - loss: 0.3696 - acc: 0.840 - ETA: 0s - loss: 0.3546 - acc: 0.853 - ETA: 0s - loss: 0.3440 - acc: 0.862 - 2s 10ms/step - loss: 0.3526 - acc: 0.8603 - val_loss: 1.2952 - val_acc: 0.6522\n",
      "Epoch 40/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4593 - acc: 0.760 - ETA: 1s - loss: 0.4507 - acc: 0.820 - ETA: 0s - loss: 0.3358 - acc: 0.880 - ETA: 0s - loss: 0.3042 - acc: 0.900 - ETA: 0s - loss: 0.3458 - acc: 0.872 - ETA: 0s - loss: 0.3456 - acc: 0.866 - ETA: 0s - loss: 0.3240 - acc: 0.885 - 2s 10ms/step - loss: 0.3218 - acc: 0.8827 - val_loss: 1.3701 - val_acc: 0.6522\n",
      "Epoch 41/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.3237 - acc: 0.920 - ETA: 1s - loss: 0.3018 - acc: 0.920 - ETA: 0s - loss: 0.3432 - acc: 0.906 - ETA: 0s - loss: 0.3588 - acc: 0.890 - ETA: 0s - loss: 0.3013 - acc: 0.904 - ETA: 0s - loss: 0.3286 - acc: 0.906 - ETA: 0s - loss: 0.3083 - acc: 0.920 - 2s 10ms/step - loss: 0.3096 - acc: 0.9162 - val_loss: 1.3376 - val_acc: 0.6739\n",
      "Epoch 42/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.1748 - acc: 0.920 - ETA: 1s - loss: 0.2338 - acc: 0.920 - ETA: 1s - loss: 0.3093 - acc: 0.933 - ETA: 0s - loss: 0.3325 - acc: 0.930 - ETA: 0s - loss: 0.3939 - acc: 0.896 - ETA: 0s - loss: 0.3768 - acc: 0.893 - ETA: 0s - loss: 0.3885 - acc: 0.874 - 2s 11ms/step - loss: 0.3810 - acc: 0.8771 - val_loss: 1.9954 - val_acc: 0.5652\n",
      "Epoch 43/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4356 - acc: 0.840 - ETA: 1s - loss: 0.4157 - acc: 0.860 - ETA: 1s - loss: 0.3161 - acc: 0.906 - ETA: 0s - loss: 0.3276 - acc: 0.900 - ETA: 0s - loss: 0.3529 - acc: 0.872 - ETA: 0s - loss: 0.3402 - acc: 0.880 - ETA: 0s - loss: 0.3263 - acc: 0.891 - 2s 11ms/step - loss: 0.3193 - acc: 0.8939 - val_loss: 1.5827 - val_acc: 0.5435\n",
      "Epoch 44/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2220 - acc: 0.960 - ETA: 1s - loss: 0.3149 - acc: 0.920 - ETA: 1s - loss: 0.2665 - acc: 0.920 - ETA: 0s - loss: 0.2661 - acc: 0.920 - ETA: 0s - loss: 0.2344 - acc: 0.936 - ETA: 0s - loss: 0.2556 - acc: 0.920 - ETA: 0s - loss: 0.2290 - acc: 0.931 - 2s 12ms/step - loss: 0.2257 - acc: 0.9330 - val_loss: 1.4699 - val_acc: 0.5870\n",
      "Epoch 45/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0912 - acc: 1.000 - ETA: 1s - loss: 0.2239 - acc: 0.940 - ETA: 1s - loss: 0.2285 - acc: 0.933 - ETA: 0s - loss: 0.2147 - acc: 0.930 - ETA: 0s - loss: 0.1813 - acc: 0.944 - ETA: 0s - loss: 0.1635 - acc: 0.953 - ETA: 0s - loss: 0.1666 - acc: 0.948 - 2s 12ms/step - loss: 0.1638 - acc: 0.9497 - val_loss: 1.6381 - val_acc: 0.6087\n",
      "Epoch 46/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.4061 - acc: 0.800 - ETA: 1s - loss: 0.2646 - acc: 0.900 - ETA: 0s - loss: 0.4508 - acc: 0.853 - ETA: 0s - loss: 0.5336 - acc: 0.810 - ETA: 0s - loss: 0.4627 - acc: 0.832 - ETA: 0s - loss: 0.3939 - acc: 0.860 - ETA: 0s - loss: 0.3834 - acc: 0.857 - 2s 10ms/step - loss: 0.3814 - acc: 0.8547 - val_loss: 1.8900 - val_acc: 0.5652\n",
      "Epoch 47/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2852 - acc: 0.880 - ETA: 1s - loss: 0.2708 - acc: 0.900 - ETA: 0s - loss: 0.2883 - acc: 0.880 - ETA: 0s - loss: 0.2471 - acc: 0.910 - ETA: 0s - loss: 0.2442 - acc: 0.928 - ETA: 0s - loss: 0.2191 - acc: 0.940 - ETA: 0s - loss: 0.2044 - acc: 0.948 - 2s 10ms/step - loss: 0.2071 - acc: 0.9441 - val_loss: 1.3394 - val_acc: 0.7174\n",
      "Epoch 48/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2968 - acc: 0.880 - ETA: 1s - loss: 0.2165 - acc: 0.920 - ETA: 0s - loss: 0.1655 - acc: 0.946 - ETA: 0s - loss: 0.1587 - acc: 0.950 - ETA: 0s - loss: 0.1533 - acc: 0.952 - ETA: 0s - loss: 0.1982 - acc: 0.933 - ETA: 0s - loss: 0.1756 - acc: 0.942 - 2s 10ms/step - loss: 0.1721 - acc: 0.9441 - val_loss: 1.6961 - val_acc: 0.6522\n",
      "Epoch 49/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.2010 - acc: 0.920 - ETA: 1s - loss: 0.1420 - acc: 0.940 - ETA: 0s - loss: 0.1172 - acc: 0.960 - ETA: 0s - loss: 0.1049 - acc: 0.970 - ETA: 0s - loss: 0.1302 - acc: 0.960 - ETA: 0s - loss: 0.1278 - acc: 0.960 - ETA: 0s - loss: 0.1223 - acc: 0.960 - 2s 10ms/step - loss: 0.1198 - acc: 0.9609 - val_loss: 1.6485 - val_acc: 0.6522\n",
      "Epoch 50/50\n",
      "179/179 [==============================] - ETA: 1s - loss: 0.0723 - acc: 1.000 - ETA: 1s - loss: 0.0693 - acc: 1.000 - ETA: 0s - loss: 0.0796 - acc: 0.986 - ETA: 0s - loss: 0.1030 - acc: 0.970 - ETA: 0s - loss: 0.1049 - acc: 0.976 - ETA: 0s - loss: 0.0967 - acc: 0.973 - ETA: 0s - loss: 0.1047 - acc: 0.971 - 2s 11ms/step - loss: 0.1046 - acc: 0.9721 - val_loss: 1.7518 - val_acc: 0.6522\n",
      "K-Fold-2\n",
      "=========================================\n",
      "Test loss: 1.7517857085103574\n",
      "Test accuracy: 0.6521739208179972\n",
      "=========================================\n",
      "\n",
      "Iterasi ke-3\n",
      "Train : [  0   1   2   4   5   6   8   9  10  11  12  14  17  18  20  21  25  26\n",
      "  27  28  29  30  32  33  34  35  37  38  39  40  41  42  43  44  45  46\n",
      "  47  48  49  50  52  53  55  56  57  58  59  60  61  62  64  65  66  68\n",
      "  70  71  72  73  74  75  76  77  79  80  81  82  84  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 104 106 107 108 109 110 111\n",
      " 112 115 116 117 118 119 120 121 122 123 124 126 127 128 129 130 131 132\n",
      " 133 134 136 137 138 139 140 142 143 144 146 147 148 149 150 152 153 154\n",
      " 156 158 160 161 164 165 167 168 169 171 172 173 174 175 176 178 180 181\n",
      " 182 184 185 186 187 188 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206 208 209 210 211 212 215 217 219 220 221 222 223 224]\n",
      "Test : [  3   7  13  15  16  19  22  23  24  31  36  51  54  63  67  69  78  83\n",
      "  85 102 103 105 113 114 125 135 141 145 151 155 157 159 162 163 166 170\n",
      " 177 179 183 189 207 213 214 216 218]\n",
      "Train on 180 samples, validate on 45 samples\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - ETA: 11s - loss: 1.7805 - acc: 0.08 - ETA: 5s - loss: 2.4917 - acc: 0.2400 - ETA: 3s - loss: 3.5312 - acc: 0.240 - ETA: 1s - loss: 3.3356 - acc: 0.220 - ETA: 1s - loss: 3.4299 - acc: 0.240 - ETA: 0s - loss: 3.1581 - acc: 0.253 - ETA: 0s - loss: 2.9604 - acc: 0.268 - 4s 20ms/step - loss: 2.9273 - acc: 0.2722 - val_loss: 1.7259 - val_acc: 0.4222\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.7473 - acc: 0.240 - ETA: 1s - loss: 1.6957 - acc: 0.340 - ETA: 0s - loss: 1.5599 - acc: 0.426 - ETA: 0s - loss: 1.6766 - acc: 0.430 - ETA: 0s - loss: 1.6452 - acc: 0.400 - ETA: 0s - loss: 1.6241 - acc: 0.373 - ETA: 0s - loss: 1.6233 - acc: 0.354 - 2s 10ms/step - loss: 1.6166 - acc: 0.3556 - val_loss: 1.6134 - val_acc: 0.2000\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.5022 - acc: 0.200 - ETA: 1s - loss: 1.5707 - acc: 0.240 - ETA: 0s - loss: 1.6025 - acc: 0.186 - ETA: 0s - loss: 1.5658 - acc: 0.230 - ETA: 0s - loss: 1.5767 - acc: 0.232 - ETA: 0s - loss: 1.5536 - acc: 0.260 - ETA: 0s - loss: 1.5732 - acc: 0.257 - 2s 10ms/step - loss: 1.5751 - acc: 0.2611 - val_loss: 1.4952 - val_acc: 0.4222\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4371 - acc: 0.320 - ETA: 1s - loss: 1.4820 - acc: 0.280 - ETA: 0s - loss: 1.4647 - acc: 0.373 - ETA: 0s - loss: 1.4394 - acc: 0.380 - ETA: 0s - loss: 1.4576 - acc: 0.376 - ETA: 0s - loss: 1.4708 - acc: 0.366 - ETA: 0s - loss: 1.4773 - acc: 0.365 - 2s 10ms/step - loss: 1.4782 - acc: 0.3667 - val_loss: 1.4814 - val_acc: 0.4222\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.5546 - acc: 0.320 - ETA: 1s - loss: 1.5193 - acc: 0.360 - ETA: 0s - loss: 1.5135 - acc: 0.386 - ETA: 0s - loss: 1.5060 - acc: 0.410 - ETA: 0s - loss: 1.4882 - acc: 0.408 - ETA: 0s - loss: 1.4689 - acc: 0.406 - ETA: 0s - loss: 1.4880 - acc: 0.400 - 2s 10ms/step - loss: 1.4815 - acc: 0.4000 - val_loss: 1.4671 - val_acc: 0.4222\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.7790 - acc: 0.240 - ETA: 1s - loss: 1.5321 - acc: 0.280 - ETA: 0s - loss: 1.5381 - acc: 0.306 - ETA: 0s - loss: 1.5127 - acc: 0.310 - ETA: 0s - loss: 1.4759 - acc: 0.344 - ETA: 0s - loss: 1.4599 - acc: 0.373 - ETA: 0s - loss: 1.4774 - acc: 0.371 - 2s 11ms/step - loss: 1.4843 - acc: 0.3722 - val_loss: 1.4880 - val_acc: 0.4222\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4910 - acc: 0.320 - ETA: 1s - loss: 1.4102 - acc: 0.420 - ETA: 1s - loss: 1.4357 - acc: 0.400 - ETA: 0s - loss: 1.4331 - acc: 0.370 - ETA: 0s - loss: 1.4549 - acc: 0.376 - ETA: 0s - loss: 1.4775 - acc: 0.353 - ETA: 0s - loss: 1.4768 - acc: 0.365 - 2s 11ms/step - loss: 1.4705 - acc: 0.3667 - val_loss: 1.4812 - val_acc: 0.4222\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2902 - acc: 0.440 - ETA: 1s - loss: 1.4255 - acc: 0.400 - ETA: 1s - loss: 1.3961 - acc: 0.426 - ETA: 0s - loss: 1.4567 - acc: 0.360 - ETA: 0s - loss: 1.5044 - acc: 0.352 - ETA: 0s - loss: 1.4809 - acc: 0.366 - ETA: 0s - loss: 1.4778 - acc: 0.382 - 2s 11ms/step - loss: 1.4758 - acc: 0.3889 - val_loss: 1.4732 - val_acc: 0.4222\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3332 - acc: 0.480 - ETA: 1s - loss: 1.3701 - acc: 0.460 - ETA: 1s - loss: 1.4724 - acc: 0.373 - ETA: 0s - loss: 1.4643 - acc: 0.410 - ETA: 0s - loss: 1.4772 - acc: 0.392 - ETA: 0s - loss: 1.4604 - acc: 0.393 - ETA: 0s - loss: 1.4503 - acc: 0.394 - 2s 11ms/step - loss: 1.4571 - acc: 0.3944 - val_loss: 1.4504 - val_acc: 0.4222\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4614 - acc: 0.360 - ETA: 1s - loss: 1.4061 - acc: 0.380 - ETA: 1s - loss: 1.4431 - acc: 0.386 - ETA: 0s - loss: 1.4223 - acc: 0.380 - ETA: 0s - loss: 1.4520 - acc: 0.376 - ETA: 0s - loss: 1.4596 - acc: 0.380 - ETA: 0s - loss: 1.4418 - acc: 0.394 - 2s 11ms/step - loss: 1.4349 - acc: 0.3944 - val_loss: 1.4520 - val_acc: 0.4222\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3124 - acc: 0.360 - ETA: 1s - loss: 1.5839 - acc: 0.300 - ETA: 0s - loss: 1.4503 - acc: 0.373 - ETA: 0s - loss: 1.5070 - acc: 0.340 - ETA: 0s - loss: 1.4850 - acc: 0.352 - ETA: 0s - loss: 1.4640 - acc: 0.360 - ETA: 0s - loss: 1.4694 - acc: 0.382 - 2s 10ms/step - loss: 1.4680 - acc: 0.3889 - val_loss: 1.4819 - val_acc: 0.4222\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3831 - acc: 0.440 - ETA: 1s - loss: 1.3671 - acc: 0.460 - ETA: 0s - loss: 1.3101 - acc: 0.493 - ETA: 0s - loss: 1.3482 - acc: 0.440 - ETA: 0s - loss: 1.4337 - acc: 0.424 - ETA: 0s - loss: 1.4578 - acc: 0.413 - ETA: 0s - loss: 1.4493 - acc: 0.394 - 2s 10ms/step - loss: 1.4425 - acc: 0.3944 - val_loss: 1.4281 - val_acc: 0.4222\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - ETA: 1s - loss: 1.3718 - acc: 0.400 - ETA: 1s - loss: 1.4242 - acc: 0.320 - ETA: 0s - loss: 1.4452 - acc: 0.346 - ETA: 0s - loss: 1.4762 - acc: 0.380 - ETA: 0s - loss: 1.4808 - acc: 0.368 - ETA: 0s - loss: 1.4569 - acc: 0.380 - ETA: 0s - loss: 1.4384 - acc: 0.388 - 2s 10ms/step - loss: 1.4392 - acc: 0.3889 - val_loss: 1.4188 - val_acc: 0.4222\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4406 - acc: 0.280 - ETA: 1s - loss: 1.4410 - acc: 0.260 - ETA: 0s - loss: 1.4274 - acc: 0.320 - ETA: 0s - loss: 1.3870 - acc: 0.350 - ETA: 0s - loss: 1.3768 - acc: 0.344 - ETA: 0s - loss: 1.3584 - acc: 0.366 - ETA: 0s - loss: 1.3766 - acc: 0.394 - 2s 11ms/step - loss: 1.3748 - acc: 0.3944 - val_loss: 1.4129 - val_acc: 0.4222\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1944 - acc: 0.600 - ETA: 1s - loss: 1.3215 - acc: 0.460 - ETA: 1s - loss: 1.3487 - acc: 0.453 - ETA: 0s - loss: 1.4109 - acc: 0.390 - ETA: 0s - loss: 1.4208 - acc: 0.392 - ETA: 0s - loss: 1.4171 - acc: 0.386 - ETA: 0s - loss: 1.3905 - acc: 0.394 - 2s 11ms/step - loss: 1.3905 - acc: 0.3944 - val_loss: 1.4045 - val_acc: 0.4222\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4729 - acc: 0.280 - ETA: 1s - loss: 1.3257 - acc: 0.400 - ETA: 1s - loss: 1.3171 - acc: 0.386 - ETA: 0s - loss: 1.2352 - acc: 0.460 - ETA: 0s - loss: 1.3400 - acc: 0.416 - ETA: 0s - loss: 1.3430 - acc: 0.426 - ETA: 0s - loss: 1.3806 - acc: 0.388 - 2s 11ms/step - loss: 1.3824 - acc: 0.3944 - val_loss: 1.4993 - val_acc: 0.4222\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4172 - acc: 0.400 - ETA: 1s - loss: 1.3753 - acc: 0.420 - ETA: 1s - loss: 1.3540 - acc: 0.426 - ETA: 0s - loss: 1.3573 - acc: 0.420 - ETA: 0s - loss: 1.3242 - acc: 0.432 - ETA: 0s - loss: 1.4143 - acc: 0.406 - ETA: 0s - loss: 1.3982 - acc: 0.400 - 2s 11ms/step - loss: 1.4078 - acc: 0.3944 - val_loss: 1.4035 - val_acc: 0.4222\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4895 - acc: 0.440 - ETA: 1s - loss: 1.3920 - acc: 0.480 - ETA: 1s - loss: 1.4104 - acc: 0.520 - ETA: 0s - loss: 1.4116 - acc: 0.470 - ETA: 0s - loss: 1.4093 - acc: 0.440 - ETA: 0s - loss: 1.4240 - acc: 0.400 - ETA: 0s - loss: 1.4116 - acc: 0.394 - 2s 11ms/step - loss: 1.4062 - acc: 0.3944 - val_loss: 1.4121 - val_acc: 0.4222\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3877 - acc: 0.480 - ETA: 1s - loss: 1.3873 - acc: 0.440 - ETA: 0s - loss: 1.3473 - acc: 0.466 - ETA: 0s - loss: 1.4017 - acc: 0.420 - ETA: 0s - loss: 1.3761 - acc: 0.432 - ETA: 0s - loss: 1.4020 - acc: 0.413 - ETA: 0s - loss: 1.3822 - acc: 0.400 - 2s 10ms/step - loss: 1.3770 - acc: 0.3944 - val_loss: 1.4197 - val_acc: 0.4222\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4403 - acc: 0.320 - ETA: 1s - loss: 1.4114 - acc: 0.300 - ETA: 0s - loss: 1.3842 - acc: 0.360 - ETA: 0s - loss: 1.3681 - acc: 0.390 - ETA: 0s - loss: 1.3718 - acc: 0.368 - ETA: 0s - loss: 1.4181 - acc: 0.353 - ETA: 0s - loss: 1.3992 - acc: 0.365 - 2s 10ms/step - loss: 1.3876 - acc: 0.3722 - val_loss: 1.4069 - val_acc: 0.4222\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3521 - acc: 0.440 - ETA: 1s - loss: 1.3922 - acc: 0.380 - ETA: 0s - loss: 1.3639 - acc: 0.386 - ETA: 0s - loss: 1.3203 - acc: 0.420 - ETA: 0s - loss: 1.3458 - acc: 0.392 - ETA: 0s - loss: 1.3679 - acc: 0.393 - ETA: 0s - loss: 1.3633 - acc: 0.400 - 2s 10ms/step - loss: 1.3652 - acc: 0.4000 - val_loss: 1.3887 - val_acc: 0.4222\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2266 - acc: 0.480 - ETA: 1s - loss: 1.2660 - acc: 0.480 - ETA: 0s - loss: 1.2331 - acc: 0.493 - ETA: 0s - loss: 1.2801 - acc: 0.480 - ETA: 0s - loss: 1.3226 - acc: 0.456 - ETA: 0s - loss: 1.3372 - acc: 0.426 - ETA: 0s - loss: 1.3263 - acc: 0.417 - 2s 10ms/step - loss: 1.3234 - acc: 0.4167 - val_loss: 1.3967 - val_acc: 0.4222\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.5939 - acc: 0.280 - ETA: 1s - loss: 1.4738 - acc: 0.280 - ETA: 1s - loss: 1.3189 - acc: 0.386 - ETA: 0s - loss: 1.3136 - acc: 0.380 - ETA: 0s - loss: 1.3398 - acc: 0.376 - ETA: 0s - loss: 1.3607 - acc: 0.373 - ETA: 0s - loss: 1.3180 - acc: 0.405 - 2s 11ms/step - loss: 1.3186 - acc: 0.4111 - val_loss: 1.4046 - val_acc: 0.4889\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2268 - acc: 0.520 - ETA: 1s - loss: 1.2614 - acc: 0.440 - ETA: 1s - loss: 1.2424 - acc: 0.453 - ETA: 0s - loss: 1.2709 - acc: 0.430 - ETA: 0s - loss: 1.2781 - acc: 0.448 - ETA: 0s - loss: 1.3399 - acc: 0.420 - ETA: 0s - loss: 1.3267 - acc: 0.422 - 2s 11ms/step - loss: 1.3250 - acc: 0.4167 - val_loss: 1.3693 - val_acc: 0.4667\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4114 - acc: 0.360 - ETA: 1s - loss: 1.3584 - acc: 0.380 - ETA: 1s - loss: 1.3533 - acc: 0.400 - ETA: 0s - loss: 1.3456 - acc: 0.400 - ETA: 0s - loss: 1.3163 - acc: 0.440 - ETA: 0s - loss: 1.2900 - acc: 0.446 - ETA: 0s - loss: 1.2899 - acc: 0.440 - 2s 11ms/step - loss: 1.2927 - acc: 0.4444 - val_loss: 1.4433 - val_acc: 0.4222\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1923 - acc: 0.480 - ETA: 1s - loss: 1.3100 - acc: 0.440 - ETA: 1s - loss: 1.3559 - acc: 0.386 - ETA: 0s - loss: 1.3437 - acc: 0.420 - ETA: 0s - loss: 1.3413 - acc: 0.416 - ETA: 0s - loss: 1.3551 - acc: 0.420 - ETA: 0s - loss: 1.3605 - acc: 0.417 - 2s 11ms/step - loss: 1.3468 - acc: 0.4278 - val_loss: 1.3735 - val_acc: 0.4667\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2973 - acc: 0.360 - ETA: 1s - loss: 1.2938 - acc: 0.400 - ETA: 1s - loss: 1.3467 - acc: 0.453 - ETA: 0s - loss: 1.4072 - acc: 0.430 - ETA: 0s - loss: 1.3511 - acc: 0.440 - ETA: 0s - loss: 1.3273 - acc: 0.440 - ETA: 0s - loss: 1.3316 - acc: 0.417 - 2s 11ms/step - loss: 1.3323 - acc: 0.4167 - val_loss: 1.3820 - val_acc: 0.4667\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2190 - acc: 0.640 - ETA: 1s - loss: 1.3185 - acc: 0.520 - ETA: 0s - loss: 1.2671 - acc: 0.506 - ETA: 0s - loss: 1.2754 - acc: 0.460 - ETA: 0s - loss: 1.3193 - acc: 0.440 - ETA: 0s - loss: 1.2977 - acc: 0.453 - ETA: 0s - loss: 1.2965 - acc: 0.445 - 2s 10ms/step - loss: 1.2933 - acc: 0.4500 - val_loss: 1.3462 - val_acc: 0.4889\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1022 - acc: 0.560 - ETA: 1s - loss: 1.1511 - acc: 0.520 - ETA: 0s - loss: 1.1812 - acc: 0.493 - ETA: 0s - loss: 1.2104 - acc: 0.480 - ETA: 0s - loss: 1.2219 - acc: 0.472 - ETA: 0s - loss: 1.2477 - acc: 0.460 - ETA: 0s - loss: 1.2596 - acc: 0.445 - 2s 10ms/step - loss: 1.2556 - acc: 0.4500 - val_loss: 1.3826 - val_acc: 0.4667\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3683 - acc: 0.400 - ETA: 1s - loss: 1.3238 - acc: 0.440 - ETA: 0s - loss: 1.2708 - acc: 0.466 - ETA: 0s - loss: 1.2907 - acc: 0.450 - ETA: 0s - loss: 1.2656 - acc: 0.464 - ETA: 0s - loss: 1.2606 - acc: 0.453 - ETA: 0s - loss: 1.2647 - acc: 0.462 - 2s 10ms/step - loss: 1.2654 - acc: 0.4611 - val_loss: 1.3159 - val_acc: 0.4667\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.0751 - acc: 0.560 - ETA: 1s - loss: 1.1514 - acc: 0.500 - ETA: 0s - loss: 1.1625 - acc: 0.533 - ETA: 0s - loss: 1.2176 - acc: 0.530 - ETA: 0s - loss: 1.2046 - acc: 0.520 - ETA: 0s - loss: 1.2209 - acc: 0.506 - ETA: 0s - loss: 1.2240 - acc: 0.508 - 2s 10ms/step - loss: 1.2250 - acc: 0.5111 - val_loss: 1.3473 - val_acc: 0.4889\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.0093 - acc: 0.480 - ETA: 1s - loss: 1.2221 - acc: 0.460 - ETA: 1s - loss: 1.4027 - acc: 0.400 - ETA: 0s - loss: 1.3658 - acc: 0.410 - ETA: 0s - loss: 1.3069 - acc: 0.440 - ETA: 0s - loss: 1.2800 - acc: 0.466 - ETA: 0s - loss: 1.2553 - acc: 0.485 - 2s 12ms/step - loss: 1.2489 - acc: 0.4889 - val_loss: 1.3803 - val_acc: 0.4000\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2352 - acc: 0.320 - ETA: 1s - loss: 1.1880 - acc: 0.380 - ETA: 1s - loss: 1.1785 - acc: 0.440 - ETA: 0s - loss: 1.2182 - acc: 0.450 - ETA: 0s - loss: 1.2264 - acc: 0.464 - ETA: 0s - loss: 1.2058 - acc: 0.486 - ETA: 0s - loss: 1.2068 - acc: 0.491 - 2s 11ms/step - loss: 1.2149 - acc: 0.4833 - val_loss: 1.3145 - val_acc: 0.5111\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.4644 - acc: 0.440 - ETA: 1s - loss: 1.3902 - acc: 0.400 - ETA: 1s - loss: 1.3473 - acc: 0.413 - ETA: 0s - loss: 1.2969 - acc: 0.450 - ETA: 0s - loss: 1.2593 - acc: 0.472 - ETA: 0s - loss: 1.2417 - acc: 0.466 - ETA: 0s - loss: 1.2339 - acc: 0.468 - 2s 11ms/step - loss: 1.2271 - acc: 0.4778 - val_loss: 1.2536 - val_acc: 0.5333\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2074 - acc: 0.560 - ETA: 1s - loss: 1.1958 - acc: 0.480 - ETA: 1s - loss: 1.2475 - acc: 0.453 - ETA: 0s - loss: 1.3756 - acc: 0.410 - ETA: 0s - loss: 1.3512 - acc: 0.448 - ETA: 0s - loss: 1.2892 - acc: 0.480 - ETA: 0s - loss: 1.2625 - acc: 0.491 - 2s 11ms/step - loss: 1.2573 - acc: 0.4944 - val_loss: 1.2680 - val_acc: 0.5556\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3067 - acc: 0.480 - ETA: 1s - loss: 1.2182 - acc: 0.500 - ETA: 1s - loss: 1.1411 - acc: 0.546 - ETA: 0s - loss: 1.1655 - acc: 0.500 - ETA: 0s - loss: 1.1336 - acc: 0.536 - ETA: 0s - loss: 1.1497 - acc: 0.513 - ETA: 0s - loss: 1.1671 - acc: 0.502 - 2s 10ms/step - loss: 1.1556 - acc: 0.5111 - val_loss: 1.2305 - val_acc: 0.6000\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.0925 - acc: 0.560 - ETA: 1s - loss: 1.0095 - acc: 0.560 - ETA: 0s - loss: 1.0654 - acc: 0.546 - ETA: 0s - loss: 1.0876 - acc: 0.540 - ETA: 0s - loss: 1.0759 - acc: 0.560 - ETA: 0s - loss: 1.0975 - acc: 0.546 - ETA: 0s - loss: 1.1383 - acc: 0.531 - 2s 10ms/step - loss: 1.1370 - acc: 0.5333 - val_loss: 1.2312 - val_acc: 0.4889\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.0096 - acc: 0.680 - ETA: 1s - loss: 1.0795 - acc: 0.560 - ETA: 0s - loss: 1.1038 - acc: 0.533 - ETA: 0s - loss: 1.1608 - acc: 0.510 - ETA: 0s - loss: 1.1256 - acc: 0.528 - ETA: 0s - loss: 1.1545 - acc: 0.513 - ETA: 0s - loss: 1.1529 - acc: 0.531 - 2s 10ms/step - loss: 1.1486 - acc: 0.5333 - val_loss: 1.2193 - val_acc: 0.5556\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2049 - acc: 0.560 - ETA: 1s - loss: 1.2185 - acc: 0.480 - ETA: 0s - loss: 1.1889 - acc: 0.440 - ETA: 0s - loss: 1.1252 - acc: 0.480 - ETA: 0s - loss: 1.1103 - acc: 0.480 - ETA: 0s - loss: 1.0960 - acc: 0.500 - ETA: 0s - loss: 1.0921 - acc: 0.497 - 2s 10ms/step - loss: 1.0936 - acc: 0.4944 - val_loss: 1.1955 - val_acc: 0.5778\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1692 - acc: 0.480 - ETA: 1s - loss: 1.0792 - acc: 0.520 - ETA: 1s - loss: 1.0823 - acc: 0.493 - ETA: 0s - loss: 1.0698 - acc: 0.520 - ETA: 0s - loss: 1.1086 - acc: 0.528 - ETA: 0s - loss: 1.1088 - acc: 0.526 - ETA: 0s - loss: 1.1133 - acc: 0.525 - 2s 11ms/step - loss: 1.1103 - acc: 0.5278 - val_loss: 1.1858 - val_acc: 0.5111\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.9687 - acc: 0.560 - ETA: 1s - loss: 1.0047 - acc: 0.560 - ETA: 1s - loss: 0.9998 - acc: 0.546 - ETA: 0s - loss: 1.0061 - acc: 0.540 - ETA: 0s - loss: 1.0122 - acc: 0.544 - ETA: 0s - loss: 1.0574 - acc: 0.500 - ETA: 0s - loss: 1.0524 - acc: 0.531 - 2s 11ms/step - loss: 1.0457 - acc: 0.5333 - val_loss: 1.1731 - val_acc: 0.5778\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.9354 - acc: 0.640 - ETA: 1s - loss: 1.0557 - acc: 0.500 - ETA: 1s - loss: 1.0250 - acc: 0.520 - ETA: 0s - loss: 1.0267 - acc: 0.500 - ETA: 0s - loss: 1.0265 - acc: 0.512 - ETA: 0s - loss: 1.0542 - acc: 0.533 - ETA: 0s - loss: 1.0396 - acc: 0.548 - 2s 11ms/step - loss: 1.0404 - acc: 0.5444 - val_loss: 1.1312 - val_acc: 0.5556\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.3576 - acc: 0.360 - ETA: 1s - loss: 1.2371 - acc: 0.480 - ETA: 1s - loss: 1.1063 - acc: 0.493 - ETA: 0s - loss: 1.0956 - acc: 0.500 - ETA: 0s - loss: 1.0724 - acc: 0.528 - ETA: 0s - loss: 1.0513 - acc: 0.553 - ETA: 0s - loss: 1.0124 - acc: 0.577 - 2s 11ms/step - loss: 1.0089 - acc: 0.5778 - val_loss: 1.1241 - val_acc: 0.5556\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1765 - acc: 0.520 - ETA: 1s - loss: 0.9735 - acc: 0.640 - ETA: 0s - loss: 0.9709 - acc: 0.626 - ETA: 0s - loss: 1.0182 - acc: 0.600 - ETA: 0s - loss: 1.0272 - acc: 0.568 - ETA: 0s - loss: 1.0241 - acc: 0.566 - ETA: 0s - loss: 1.0154 - acc: 0.577 - 2s 10ms/step - loss: 1.0333 - acc: 0.5611 - val_loss: 1.1441 - val_acc: 0.5333\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.8992 - acc: 0.600 - ETA: 1s - loss: 0.9643 - acc: 0.520 - ETA: 1s - loss: 1.0726 - acc: 0.520 - ETA: 0s - loss: 1.0357 - acc: 0.530 - ETA: 0s - loss: 0.9966 - acc: 0.560 - ETA: 0s - loss: 0.9961 - acc: 0.553 - ETA: 0s - loss: 1.0275 - acc: 0.542 - 2s 11ms/step - loss: 1.0321 - acc: 0.5444 - val_loss: 1.2719 - val_acc: 0.4889\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.2732 - acc: 0.280 - ETA: 1s - loss: 1.2630 - acc: 0.360 - ETA: 0s - loss: 1.2177 - acc: 0.373 - ETA: 0s - loss: 1.1572 - acc: 0.460 - ETA: 0s - loss: 1.1558 - acc: 0.480 - ETA: 0s - loss: 1.0942 - acc: 0.520 - ETA: 0s - loss: 1.0678 - acc: 0.531 - 2s 10ms/step - loss: 1.0767 - acc: 0.5278 - val_loss: 1.1424 - val_acc: 0.6000\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 1.1943 - acc: 0.480 - ETA: 1s - loss: 1.0103 - acc: 0.600 - ETA: 1s - loss: 1.0429 - acc: 0.586 - ETA: 0s - loss: 0.9944 - acc: 0.580 - ETA: 0s - loss: 1.0122 - acc: 0.592 - ETA: 0s - loss: 1.0010 - acc: 0.600 - ETA: 0s - loss: 0.9612 - acc: 0.611 - 2s 11ms/step - loss: 0.9687 - acc: 0.6056 - val_loss: 1.1791 - val_acc: 0.6000\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.8683 - acc: 0.640 - ETA: 1s - loss: 0.9106 - acc: 0.560 - ETA: 1s - loss: 0.9262 - acc: 0.600 - ETA: 0s - loss: 0.9210 - acc: 0.610 - ETA: 0s - loss: 0.9066 - acc: 0.616 - ETA: 0s - loss: 0.9205 - acc: 0.613 - ETA: 0s - loss: 0.9349 - acc: 0.600 - 2s 11ms/step - loss: 0.9461 - acc: 0.5944 - val_loss: 1.1099 - val_acc: 0.6000\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.7421 - acc: 0.760 - ETA: 1s - loss: 0.8202 - acc: 0.640 - ETA: 1s - loss: 0.8685 - acc: 0.600 - ETA: 0s - loss: 0.8996 - acc: 0.580 - ETA: 0s - loss: 0.9249 - acc: 0.584 - ETA: 0s - loss: 0.9585 - acc: 0.580 - ETA: 0s - loss: 0.9452 - acc: 0.577 - 2s 11ms/step - loss: 0.9369 - acc: 0.5778 - val_loss: 1.1664 - val_acc: 0.5556\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - ETA: 1s - loss: 0.9939 - acc: 0.640 - ETA: 1s - loss: 0.9135 - acc: 0.620 - ETA: 1s - loss: 1.0087 - acc: 0.560 - ETA: 0s - loss: 0.9890 - acc: 0.590 - ETA: 0s - loss: 1.0147 - acc: 0.584 - ETA: 0s - loss: 0.9925 - acc: 0.593 - ETA: 0s - loss: 0.9876 - acc: 0.582 - 2s 11ms/step - loss: 0.9752 - acc: 0.5944 - val_loss: 1.1064 - val_acc: 0.6000\n",
      "K-Fold-3\n",
      "=========================================\n",
      "Test loss: 1.1064268350601196\n",
      "Test accuracy: 0.5999999973509047\n",
      "=========================================\n",
      "\n",
      "Iterasi ke-4\n",
      "Train : [  0   1   2   3   4   5   6   7   8  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  27  28  29  30  31  32  33  34  36  37  38  40\n",
      "  41  42  43  47  49  50  51  52  53  54  56  57  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  77  78  80  81  83  84  85\n",
      "  86  88  89  90  91  92  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 113 114 115 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 131 133 134 135 137 138 139 140 141 142 144 145 146 147\n",
      " 148 150 151 152 154 155 156 157 158 159 160 161 162 163 165 166 168 169\n",
      " 170 171 172 175 176 177 178 179 180 181 182 183 185 189 190 191 192 193\n",
      " 196 199 201 202 203 204 207 208 213 214 215 216 217 218 219 220 221 222\n",
      " 224]\n",
      "Test : [  9  10  26  35  39  44  45  46  48  55  58  76  79  82  87  93 112 116\n",
      " 130 132 136 143 149 153 164 167 173 174 184 186 187 188 194 195 197 198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 200 205 206 209 210 211 212 223]\n",
      "Train on 181 samples, validate on 44 samples\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - ETA: 11s - loss: 1.8073 - acc: 0.04 - ETA: 5s - loss: 1.7478 - acc: 0.1800 - ETA: 3s - loss: 3.4405 - acc: 0.213 - ETA: 2s - loss: 4.4918 - acc: 0.270 - ETA: 1s - loss: 5.5360 - acc: 0.288 - ETA: 0s - loss: 6.6550 - acc: 0.280 - ETA: 0s - loss: 7.2700 - acc: 0.285 - 4s 20ms/step - loss: 7.5633 - acc: 0.2762 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 11.9274 - acc: 0.26 - ETA: 0s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.7333 - acc: 0.21 - ETA: 0s - loss: 12.7655 - acc: 0.20 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 12.7655 - acc: 0.20 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.8616 - acc: 0.14 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.8616 - acc: 0.14 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.7655 - acc: 0.20 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 12ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.7333 - acc: 0.21 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.1708 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 12.7333 - acc: 0.21 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 12.4109 - acc: 0.23 - ETA: 0s - loss: 12.5076 - acc: 0.22 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.7004 - acc: 0.15 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 12.7333 - acc: 0.21 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.1708 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.4109 - acc: 0.23 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.7870 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 11.8199 - acc: 0.26 - ETA: 0s - loss: 12.0886 - acc: 0.25 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.8616 - acc: 0.14 - ETA: 1s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.4103 - acc: 0.16 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.8286 - acc: 0.08 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 15.4734 - acc: 0.04 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 11.9274 - acc: 0.26 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.4103 - acc: 0.16 - ETA: 0s - loss: 13.4317 - acc: 0.16 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.6681 - acc: 0.15 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 12.0886 - acc: 0.25 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 12ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 0s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 11.9274 - acc: 0.26 - ETA: 0s - loss: 12.5076 - acc: 0.22 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.5076 - acc: 0.22 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.7870 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.8286 - acc: 0.08 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.8286 - acc: 0.08 - ETA: 1s - loss: 14.5063 - acc: 0.10 - ETA: 0s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.7333 - acc: 0.21 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 12.4647 - acc: 0.22 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.4103 - acc: 0.16 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.0787 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 12ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.6796 - acc: 0.21 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 12ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 13.8616 - acc: 0.14 - ETA: 1s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.5721 - acc: 0.22 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 12.7870 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 15.4734 - acc: 0.04 - ETA: 1s - loss: 13.8616 - acc: 0.14 - ETA: 0s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.8616 - acc: 0.14 - ETA: 0s - loss: 13.7541 - acc: 0.14 - ETA: 0s - loss: 13.5392 - acc: 0.16 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 13.4317 - acc: 0.16 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 11.9274 - acc: 0.26 - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 0s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 12.6366 - acc: 0.21 - ETA: 0s - loss: 13.0019 - acc: 0.19 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 13.5392 - acc: 0.16 - ETA: 1s - loss: 12.5721 - acc: 0.22 - ETA: 1s - loss: 13.3243 - acc: 0.17 - ETA: 0s - loss: 13.3780 - acc: 0.17 - ETA: 0s - loss: 13.0234 - acc: 0.19 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.0557 - acc: 0.19 - ETA: 0s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 12.7870 - acc: 0.20 - ETA: 0s - loss: 12.9866 - acc: 0.19 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 1s - loss: 11.9274 - acc: 0.26 - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 13.2813 - acc: 0.17 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.1708 - acc: 0.18 - 2s 11ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 14.1839 - acc: 0.12 - ETA: 1s - loss: 13.2168 - acc: 0.18 - ETA: 1s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 13.2168 - acc: 0.18 - ETA: 0s - loss: 13.1524 - acc: 0.18 - ETA: 0s - loss: 13.1094 - acc: 0.18 - ETA: 0s - loss: 12.8945 - acc: 0.20 - 2s 10ms/step - loss: 13.0013 - acc: 0.1934 - val_loss: 12.4549 - val_acc: 0.2273\n",
      "K-Fold-4\n",
      "=========================================\n",
      "Test loss: 12.454891920089722\n",
      "Test accuracy: 0.227272724902088\n",
      "=========================================\n",
      "\n",
      "Iterasi ke-5\n",
      "Train : [  0   2   3   4   5   6   7   9  10  11  12  13  14  15  16  18  19  20\n",
      "  21  22  23  24  25  26  29  31  32  34  35  36  37  38  39  41  42  43\n",
      "  44  45  46  47  48  49  51  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  66  67  68  69  70  73  74  76  78  79  80  81  82  83  85  87\n",
      "  92  93  94  95  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      " 112 113 114 115 116 118 119 120 123 124 125 127 128 129 130 131 132 133\n",
      " 134 135 136 139 141 142 143 145 148 149 150 151 153 154 155 156 157 158\n",
      " 159 160 162 163 164 165 166 167 169 170 171 172 173 174 176 177 178 179\n",
      " 180 181 182 183 184 186 187 188 189 190 192 193 194 195 196 197 198 200\n",
      " 201 202 203 204 205 206 207 209 210 211 212 213 214 216 218 219 220 223\n",
      " 224]\n",
      "Test : [  1   8  17  27  28  30  33  40  50  65  71  72  75  77  84  86  88  89\n",
      "  90  91  96  97 117 121 122 126 137 138 140 144 146 147 152 161 168 175\n",
      " 185 191 199 208 215 217 221 222]\n",
      "Train on 181 samples, validate on 44 samples\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - ETA: 12s - loss: 1.8043 - acc: 0.16 - ETA: 5s - loss: 2.1999 - acc: 0.2400 - ETA: 3s - loss: 3.7770 - acc: 0.226 - ETA: 2s - loss: 5.4369 - acc: 0.250 - ETA: 1s - loss: 6.0258 - acc: 0.296 - ETA: 0s - loss: 6.7408 - acc: 0.306 - ETA: 0s - loss: 7.2515 - acc: 0.314 - 4s 21ms/step - loss: 7.3673 - acc: 0.3149 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 10.1007 - acc: 0.37 - ETA: 0s - loss: 9.5097 - acc: 0.4100 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 8.7038 - acc: 0.4600 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 10.7454 - acc: 0.33 - ETA: 0s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.0577 - acc: 0.37 - ETA: 0s - loss: 9.5634 - acc: 0.4067 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.6379 - acc: 0.34 - ETA: 0s - loss: 9.9287 - acc: 0.3840 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 9.9932 - acc: 0.3800 - ETA: 0s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.7783 - acc: 0.393 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 9.6709 - acc: 0.4000 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7998 - acc: 0.392 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.9932 - acc: 0.3800 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 12ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 7.0920 - acc: 0.560 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 1s - loss: 9.3485 - acc: 0.420 - ETA: 1s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.1873 - acc: 0.430 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 1s - loss: 8.8112 - acc: 0.453 - ETA: 0s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 8.8972 - acc: 0.448 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 1s - loss: 9.3485 - acc: 0.420 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.1873 - acc: 0.430 - ETA: 0s - loss: 9.1551 - acc: 0.432 - ETA: 0s - loss: 9.7783 - acc: 0.393 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 10.1007 - acc: 0.37 - ETA: 0s - loss: 9.8320 - acc: 0.3900 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.9932 - acc: 0.380 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 10.1544 - acc: 0.37 - ETA: 0s - loss: 9.6709 - acc: 0.4000 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 1s - loss: 11.6050 - acc: 0.28 - ETA: 0s - loss: 11.1752 - acc: 0.30 - ETA: 0s - loss: 10.6379 - acc: 0.34 - ETA: 0s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 9.9932 - acc: 0.3800 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.5305 - acc: 0.34 - ETA: 0s - loss: 9.8320 - acc: 0.3900 - ETA: 0s - loss: 9.7998 - acc: 0.392 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 8.3814 - acc: 0.480 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 9.6709 - acc: 0.4000 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 8.8650 - acc: 0.450 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.8320 - acc: 0.390 - ETA: 0s - loss: 9.7998 - acc: 0.392 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 7.7367 - acc: 0.520 - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 1s - loss: 8.5963 - acc: 0.466 - ETA: 0s - loss: 9.1873 - acc: 0.430 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 5.1578 - acc: 0.680 - ETA: 1s - loss: 8.0590 - acc: 0.500 - ETA: 0s - loss: 8.5963 - acc: 0.466 - ETA: 0s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 8.7682 - acc: 0.456 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 12.8945 - acc: 0.20 - ETA: 1s - loss: 12.2498 - acc: 0.24 - ETA: 0s - loss: 10.5305 - acc: 0.34 - ETA: 0s - loss: 9.6709 - acc: 0.4000 - ETA: 0s - loss: 9.2840 - acc: 0.424 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.7454 - acc: 0.33 - ETA: 0s - loss: 10.6379 - acc: 0.34 - ETA: 0s - loss: 9.9287 - acc: 0.3840 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 0s - loss: 8.1665 - acc: 0.493 - ETA: 0s - loss: 8.3814 - acc: 0.480 - ETA: 0s - loss: 8.7682 - acc: 0.456 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.9932 - acc: 0.380 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 8.8650 - acc: 0.450 - ETA: 0s - loss: 9.1551 - acc: 0.432 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 10.4768 - acc: 0.35 - ETA: 0s - loss: 10.1866 - acc: 0.36 - ETA: 0s - loss: 10.1007 - acc: 0.37 - ETA: 0s - loss: 9.5788 - acc: 0.4057 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 8.8650 - acc: 0.450 - ETA: 0s - loss: 9.1551 - acc: 0.432 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 9.8858 - acc: 0.3867 - ETA: 0s - loss: 9.8320 - acc: 0.390 - ETA: 0s - loss: 10.1866 - acc: 0.36 - ETA: 0s - loss: 9.7783 - acc: 0.3933 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 12ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 7.0920 - acc: 0.560 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 0s - loss: 8.5963 - acc: 0.466 - ETA: 0s - loss: 8.7038 - acc: 0.460 - ETA: 0s - loss: 9.1551 - acc: 0.432 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 6.4472 - acc: 0.600 - ETA: 1s - loss: 7.4143 - acc: 0.540 - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 0s - loss: 9.1873 - acc: 0.430 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.7783 - acc: 0.393 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 8.3814 - acc: 0.480 - ETA: 1s - loss: 8.7038 - acc: 0.460 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.8320 - acc: 0.390 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.7783 - acc: 0.393 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.9932 - acc: 0.3800 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 10.1007 - acc: 0.37 - ETA: 0s - loss: 9.6709 - acc: 0.4000 - 2s 13ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.9932 - acc: 0.3800 - ETA: 1s - loss: 10.7454 - acc: 0.33 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 9.9287 - acc: 0.3840 - ETA: 0s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 14ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.9932 - acc: 0.380 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 10.1866 - acc: 0.36 - ETA: 0s - loss: 9.7783 - acc: 0.3933 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 3s 15ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - ETA: 2s - loss: 7.7367 - acc: 0.520 - ETA: 1s - loss: 8.0590 - acc: 0.500 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 1s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.7998 - acc: 0.392 - ETA: 0s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 3s 15ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 10.1544 - acc: 0.37 - ETA: 0s - loss: 9.6709 - acc: 0.4000 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 12ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.6709 - acc: 0.4000 - ETA: 1s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.5634 - acc: 0.406 - ETA: 0s - loss: 9.8551 - acc: 0.388 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 8.8112 - acc: 0.453 - ETA: 0s - loss: 8.8650 - acc: 0.450 - ETA: 0s - loss: 9.2840 - acc: 0.424 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.4130 - acc: 0.416 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.1873 - acc: 0.430 - ETA: 0s - loss: 9.2840 - acc: 0.424 - ETA: 0s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.1544 - acc: 0.37 - ETA: 0s - loss: 9.7998 - acc: 0.3920 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 12ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 7.0920 - acc: 0.560 - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 10.1866 - acc: 0.36 - ETA: 0s - loss: 9.7783 - acc: 0.3933 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 11.2827 - acc: 0.30 - ETA: 1s - loss: 10.7454 - acc: 0.33 - ETA: 0s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 10.1866 - acc: 0.36 - ETA: 0s - loss: 9.8858 - acc: 0.3867 - ETA: 0s - loss: 9.5788 - acc: 0.405 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 9.0261 - acc: 0.440 - ETA: 1s - loss: 9.3485 - acc: 0.420 - ETA: 0s - loss: 9.2410 - acc: 0.426 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.6709 - acc: 0.400 - ETA: 0s - loss: 9.8858 - acc: 0.386 - ETA: 0s - loss: 9.9472 - acc: 0.382 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 11.9274 - acc: 0.26 - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 0s - loss: 10.1544 - acc: 0.37 - ETA: 0s - loss: 9.9287 - acc: 0.3840 - ETA: 0s - loss: 9.7783 - acc: 0.393 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.9603 - acc: 0.32 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.0261 - acc: 0.4400 - ETA: 0s - loss: 9.5097 - acc: 0.410 - ETA: 0s - loss: 9.0261 - acc: 0.440 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.6709 - acc: 0.400 - 2s 11ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 7.7367 - acc: 0.520 - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 10.1007 - acc: 0.37 - ETA: 0s - loss: 9.9932 - acc: 0.3800 - ETA: 0s - loss: 9.5419 - acc: 0.408 - ETA: 0s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.8551 - acc: 0.388 - 2s 10ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - ETA: 1s - loss: 10.3156 - acc: 0.36 - ETA: 1s - loss: 9.9932 - acc: 0.3800 - ETA: 1s - loss: 9.4559 - acc: 0.413 - ETA: 0s - loss: 9.9932 - acc: 0.380 - ETA: 0s - loss: 10.3156 - acc: 0.36 - ETA: 0s - loss: 9.9932 - acc: 0.3800 - ETA: 0s - loss: 9.7630 - acc: 0.394 - 2s 12ms/step - loss: 9.7065 - acc: 0.3978 - val_loss: 9.5243 - val_acc: 0.4091\n",
      "K-Fold-5\n",
      "=========================================\n",
      "Test loss: 9.524328556927768\n",
      "Test accuracy: 0.40909091383218765\n",
      "=========================================\n",
      "\n",
      "Weight dengan akurasi tertinggi = KFold 1\n"
     ]
    }
   ],
   "source": [
    "counter=1\n",
    "max_acc = 0\n",
    "highest_model = 0\n",
    "seed = 6\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=NUM_KFOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "adam = Adam(lr=1e-3)\n",
    "epoch=50\n",
    "batchsize = 25\n",
    "\n",
    "for train_index, test_index in kfold.split(x, y[:,0]):\n",
    "    print(\"Iterasi ke-{}\".format(counter))\n",
    "    print(\"Train : {}\\nTest : {}\".format(train_index, test_index))\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Menyimpan index training masing-masing fold\n",
    "    np.savetxt('out_ulos/cv_train_ulos-'+str(counter)+'.csv', train_index, fmt='%d', delimiter=',')\n",
    "    np.savetxt('out_ulos/cv_test_ulos-'+str(counter)+'.csv', test_index, fmt='%d', delimiter=',')\n",
    "    \n",
    "    model = createModel()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    hist = model.fit(X_train, y_train, epochs=epoch, batch_size=batchsize, validation_data=(X_test, y_test), verbose=1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=batchsize, verbose=0)\n",
    "    \n",
    "    #Menyimpan model masing-masing fold\n",
    "    model.save('out_ulos/K-Fold-model-'+str(counter)+'.h5')\n",
    "    \n",
    "    #Menyimpan history model masing-masing fold\n",
    "    with open('out_ulos/hist-model-'+str(counter), 'wb') as f:\n",
    "        pickle.dump(hist.history, f)\n",
    "        \n",
    "    print('K-Fold-{}'.format(counter))\n",
    "    print('=========================================')\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('=========================================\\n')\n",
    "    \n",
    "    if score[1] > max_acc:\n",
    "        max_acc = score[1]\n",
    "        highest_model = counter\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    counter+=1\n",
    "\n",
    "#Menampilkan k-fold ke berapa yang menghasilkan accuracy paling tinggi\n",
    "print(\"Weight dengan akurasi tertinggi = KFold {}\".format(highest_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model yang memiliki accuracy tertinggi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('out_ulos/K-Fold-model-'+str(highest_model)+'.h5')\n",
    "\n",
    "#Memuat index data training dan testing dari fold yang memiliki akurasi tertinggi \n",
    "i_train = pd.read_csv(\"out_ulos/cv_train_ulos-\"+str(highest_model)+\".csv\", names=['index_train'], header=None)\n",
    "i_test = pd.read_csv(\"out_ulos/cv_test_ulos-\"+str(highest_model)+\".csv\", names=['index_test'], header=None)\n",
    "X_train, X_test = x[i_train.values.flatten()], x[i_test.values.flatten()]\n",
    "y_train, y_test = y[i_train.values.flatten()], y[i_test.values.flatten()]\n",
    "\n",
    "#Membuka history model\n",
    "with open('out_ulos/hist-model-'+str(highest_model), 'rb') as f:\n",
    "    hist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan kembali accuracy dan loss pada model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Test loss: 1.501426849676215\n",
      "Test accuracy: 0.739130437374115\n",
      "=========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_test, y_test, batch_size=batchsize, verbose=0)\n",
    "print('=========================================')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('=========================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan plot history accuracy dan loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(hist['acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melakukan validasi model dengan gambar dari masing-masing kelas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = ['Bintang Maratur', 'Mangiring', 'Ragi Hotang', 'Ragi Idup', 'Sadum', 'Sibolang']\n",
    "bm = 'ulos/validasi/bm.11.png'\n",
    "hotang = 'ulos/validasi/hotang.49.png'\n",
    "idup = 'ulos/validasi/idup.2.jpg'\n",
    "mangiring = 'ulos/validasi/mangiring.1.png'\n",
    "sadum = 'ulos/validasi/sadum.13.jpg'\n",
    "sibolang = 'ulos/validasi/sibolang.2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Bintang Maratur [0])\n",
    "img_test = cv2.imread(bm, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Mangiring [1])\n",
    "img_test = cv2.imread(mangiring, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Ragi Hotang [2])\n",
    "img_test = cv2.imread(hotang, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Ragi Idup [3])\n",
    "img_test = cv2.imread(idup, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Sadum [4])\n",
    "img_test = cv2.imread(sadum, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "#Validasi gambar (kelas Sibolang [5])\n",
    "img_test = cv2.imread(sibolang, cv2.IMREAD_COLOR)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test, (IMG_SIZE, IMG_SIZE))\n",
    "img_test = img_test.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "class_pred = loaded_model.predict_classes(img_test)\n",
    "print(class_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menampilkan summary model dan menyimpan ke dalam file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 611,014\n",
      "Trainable params: 611,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()\n",
    "with open('out_ulos/modelsummary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
